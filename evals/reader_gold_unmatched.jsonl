{"case_id": "why_path_tsv", "query": "Why did we add documents.path_tsv and use ts_rank(..., 32) in retrieval?", "answers": ["To rank by directory semantics with a GIN-indexed tsvector and normalize for length so long prose doesn't dominate."], "tag": "rag_qa_single"}
{"case_id": "bm25_hints_policy", "query": "Why do we keep BM25 'pure' and put hints only in short/title?", "answers": ["Appending hint bags to BM25 flattens tf-idf and lets generic docs win; short/title hinting boosts precision without distorting BM25."], "tag": "rag_qa_single"}
{"case_id": "mmr_cap_effect", "query": "What problem do MMR and a per-file cap solve in our retriever?", "answers": ["They prevent one README or single file from monopolizing top-K by rewarding novelty and capping repeats per file."], "tag": "rag_qa_single"}
{"case_id": "db_adjacent_phrases", "query": "When and why do we use 'create <-> index' and 'alter <-> table' adjacency?", "answers": ["Only for db_workflows to add precise phrase matches that lift SQL artifacts without leaking answers."], "tag": "db_workflows"}
{"case_id": "filename_microboost", "query": "What is the filename micro-boost and when does it trigger?", "answers": ["A tiny +0.05 prior when the query tokens match the filename; it breaks ties toward the right artifact without overfitting."], "tag": "rag_qa_single"}
{"case_id": "vector_ops_selection", "query": "How do we pick the correct vector similarity expression?", "answers": ["We switch by PGVECTOR_OPS: cosine\u21921-(<=>), L2\u21921/(1+<=>), IP\u2192-<=>; keeps semantics correct regardless of index ops."], "tag": "rag_qa_single"}
{"case_id": "sentence_compaction", "query": "What does the sentence selection step do before the reader?", "answers": ["It scores sentences by token overlap, phrase hits, and filename tokens, then keeps ~10\u201312 best lines to reduce noise and improve precision."], "tag": "rag_qa_single"}
