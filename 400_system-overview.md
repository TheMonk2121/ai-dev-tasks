<!-- CONTEXT_REFERENCE: 400_context-priority-guide.md -->
<!-- MODULE_REFERENCE: 100_cursor-memory-context.md -->
<!-- MODULE_REFERENCE: 000_backlog.md -->
<!-- MODULE_REFERENCE: 400_context-priority-guide.md -->

# System Overview

## ğŸ” TL;DR

- What: Macro view of architecture, components, and workflows
- Who: Read after memory and backlog to understand system shape
- Key: Architecture, core components, workflow, security, performance
- How: Follow the critical path, then jump to the topic you need
- Next: Use the topic table below to navigate fast

## ğŸ§­ Critical Path

1) `100_cursor-memory-context.md` â†’ 2) `000_backlog.md` â†’ 3) `400_system-overview.md` â†’ 4) topic guide (testing/deploy/integration/etc.)

## ğŸ—ºï¸ Map of Topics

| Topic | Anchor | Why | Next |
|---|---|---|---|
| Architecture | #architecture | Mental model of the system | Dive into core components |
| Core components | #core-components | What runs where | See testing, performance |
| Workflow | #workflow | How work flows end-to-end | Backlog â†’ PRD â†’ Tasks â†’ Execute |
| Security | #security | Safety, validation, monitoring | Security guide (400_security-best-practices.md) |
| Performance | #performance | Metrics, tuning, troubleshooting | Performance guide |
| Integration | #integration | Component/API integration | Integration guide |
| Deployment | #deployment | Procedures and environments | Deployment guide |
| Migration | #migration | Changes and rollbacks | Migration guide |
| Testing | #testing | Strategy and gates | Testing guide |

<!-- ANCHOR: architecture -->
<a id="architecture"></a>

## Architecture

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”§ Core Systems                                            â”‚
â”‚  â”œâ”€â”€ DSPy RAG System (Document Processing)                  â”‚
â”‚  â”œâ”€â”€ N8N Workflows (Automation)                             â”‚
â”‚  â”œâ”€â”€ Dashboard (Monitoring)                                  â”‚
â”‚  â””â”€â”€ Testing Framework (Quality Assurance)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š Supporting Infrastructure                                â”‚
â”‚  â”œâ”€â”€ PostgreSQL + PGVector (Data Storage)                   â”‚
â”‚  â”œâ”€â”€ File Watching (Document Processing)                     â”‚
â”‚  â”œâ”€â”€ Notification System (Alerts)                           â”‚
â”‚  â””â”€â”€ Error Recovery (HotFix Generation)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```text

---

<!-- ANCHOR: security -->
<a id="security"></a>

## ğŸ”’ Security & Reliability Features

### **Security Measures**

- **Prompt sanitisation**: Regex-based block-list with optional whitelist
- **File validation**: Configurable size limits with environment override
- **Input validation**: Comprehensive sanitization across all modules
- **Secrets management**: Environment-based credential handling
- **Error handling**: Configurable retry policies with fatal error detection
- **Production monitoring**: Real-time security event tracking and alerting
- **Health checks**: Kubernetes-ready health endpoints with dependency monitoring
- **System metrics**: CPU, memory, disk, and network usage monitoring
- **Database resilience**: Connection pooling with health monitoring and retry logic

### **Reliability Features**

- **Agent-level LLM timeout**: Large models = 90s (configurable per agent)
- **Global timeouts**: Centralized configuration for all operations
- **Resource management**: RAM pressure checks and model janitor
- **Structured logging**: Comprehensive audit trail with sensitive data redaction
- **Database resilience**: Connection pooling with health monitoring and retry logic
- **Error recovery**: Graceful degradation and comprehensive error handling

---

<!-- ANCHOR: workflow -->
<a id="workflow"></a>

## ğŸ”„ Development Workflow (High-Level Process)

### Phase 1: Planning & Requirements

1. **Backlog Selection** â†’ Choose feature from structured table (B-001, B-002, etc.)
2. **Idea Input** â†’ User describes feature/requirement (or use backlog item)
3. **PRD Creation** â†’ AI generates comprehensive requirements document
4. **Task Breakdown** â†’ AI creates detailed, AI-optimized task list
5. **Dependency Mapping** â†’ Tasks ordered with clear dependencies
6. **Status Update** â†’ Update backlog status as work progresses

### Phase 2: AI Execution

1. **State Loading** â†’ AI loads context from `.ai_state.json` (when using 003)
2. **Task Selection** â†’ AI picks next executable task OR executes backlog item directly
3. **Implementation** â†’ Cursor Native AI writes code, Specialized Agents provide enhancements
4. **Extraction** â†’ LangExtract handles entity/attribute extraction upstream of semantic-gravity scoring
5. **Validation** â†’ AI runs tests and validates completion
6. **State Update** â†’ Progress saved, next task selected (when using 003)

### Phase 3: Quality & Deployment

1. **Error Recovery** â†’ HotFix tasks for failed validations
2. **Human Checkpoints** â†’ Strategic pauses for high-risk operations
3. **Deployment** â†’ Automated deployment with monitoring
4. **Feedback Integration** â†’ Continuous improvement loop

---

<!-- ANCHOR: core-components -->
<a id="core-components"></a>

## ğŸ§© Core Components (Detailed View)

### 1. Planning & Management System

#### **Backlog Management Engine** (`000_backlog.md` + `100_backlog-guide.md`)

#### **Extraction Pipeline** (LangExtract + n8n Integration)

- **Purpose**: Machine-readable roadmap for systematic feature development
- **Input**: Comprehensive analysis of system needs and opportunities
- **Output**: Structured table with IDs, points, status, and metadata
- **Features**:
  - Machine-readable table format (B-001, B-002, etc.)
  - Points-based effort estimation (1, 2, 3, 5, 8, 13)
  - Status tracking (todo, in-progress, done)
  - Dependency mapping and tech footprint
  - AI-BACKLOG-META automation commands
  - **AI Scoring System**: Automated prioritization using `(BV + TC + RR + LE) / Effort` formula
  - **Score Metadata**: HTML comments with scoring data for AI parsing
  - **n8n Scrubber Workflow**: Automated score calculation and updates

#### **File Organization System** (`200_naming-conventions.md`)

- **Purpose**: Maintain consistent file organization and naming
- **Features**:
  - Structured naming conventions (00-09, 100-199, 200-299, etc.)
  - Category-based file organization
  - Scalable structure for future additions
  - Clear guidelines for contributors

#### **PRD Creation Engine** (`001_create-prd.md`)

- **Purpose**: Transform user ideas into structured requirements
- **Input**: Natural language feature descriptions or backlog items
- **Output**: Comprehensive PRD with testing strategy and acceptance criteria
- **AI Optimization**: Includes machine-verifiable completion criteria

#### **Task Generation Engine** (`002_generate-tasks.md`)

- **Purpose**: Break PRDs into AI-executable tasks
- **Features**: 
  - 2-4 hour timeboxes for efficiency
  - Clear dependencies and priorities
  - Strategic human checkpoints
  - Machine-verifiable completion criteria

#### **Process Management Engine** (`003_process-task-list.md`)

- **Purpose**: Execute tasks with AI agents
- **Features**:
  - State caching with `.ai_state.json`
  - Auto-advance for routine tasks
  - HotFix generation for error recovery
  - Strategic human oversight

#### **File Organization System** (`200_naming-conventions.md`)

- **Purpose**: Maintain consistent file organization and naming
- **Features**:
  - Structured naming conventions (00-09, 100-199, 200-299, etc.)
  - Category-based file organization
  - Scalable structure for future additions
  - Clear guidelines for contributors

### **AI Scoring & Automation System**

#### **Scoring Engine**

- **Formula**: `(Business Value + Time Criticality + Risk Reduction + Learning Enablement) / Effort`
- **Score Ranges**: 5.0+ (ğŸ”¥), 3.0-4.9 (â­), 1.5-2.9 (ğŸ“ˆ), <1.5 (ğŸ”§)
- **Metadata Format**: HTML comments with JSON scoring data
- **AI Integration**: Automatic parsing and prioritization by AI agents
- **Fallback System**: Human priority tags when scores are missing

#### **n8n Backlog Scrubber Workflow**

- **Purpose**: Automate score calculation and backlog maintenance
- **Features**:
  - Reads backlog.md file and parses scoring metadata
  - Calculates new scores using the scoring formula
  - Updates `<!--score_total: X.X-->` comments automatically
  - Handles missing metadata gracefully
  - Provides audit trail for all changes
- **Integration**: Works with AI-BACKLOG-META system for seamless automation

### 2. AI Execution Layer

#### **v0.3.1 Ultra-Minimal Router Architecture**

- **Core Agents**: IntentRouter, RetrievalAgent, CodeAgent
- **Model Management**: 
  - Cursor Native AI (foundation - always available)
- Specialized Agents (enhancements - load on demand)
- **Runtime Guard-Rails**: RAM pressure checks and model janitor
- **Fast-Path Bypass**: Skip complex routing for simple queries (<50 chars)
- **Feature Flags**: DEEP_REASONING=0, CLARIFIER=0 (default)
- **Error Policy & Retries**: Configurable retry with backoff
- **Agent-level LLM timeout**: Large models = 90s (configurable per agent)
- **Environment Variables**: POOL_MIN/POOL_MAX, MODEL_IDLE_EVICT_SECS, MAX_RAM_PRESSURE

#### **Cursor Native AI Agent**

- **Role**: Planning, reasoning, and human interaction
- **Responsibilities**:
  - Parse PRDs and generate tasks
  - Manage state and dependencies
  - Handle human checkpoints
  - Generate HotFix tasks
  - **Parse backlog scoring** for prioritization decisions
  - **Use score metadata** to inform task selection

#### **Specialized Agents**

- **Role**: Code implementation and technical execution
- **Responsibilities**:
  - Write and test code
  - Implement features
  - Debug and optimize
  - Validate completion criteria
  - **Consider scoring data** for implementation priorities

#### **State Management System**

- **File**: `.ai_state.json`
- **Purpose**: Maintain context across task boundaries
- **Data**: File lists, commit hashes, test results, progress tracking

### 3. Core AI Systems

#### **DSPy RAG System** (`dspy-rag-system/`)

- **Purpose**: Intelligent document processing and question answering
- **Architecture**: v0.3.1 Ultra-Minimal Router with progressive complexity
- **Components**:
  - Document processor with metadata extraction
  - Vector store with PostgreSQL + PGVector
  - Enhanced RAG system with DSPy integration
  - Dashboard for monitoring and interaction
  - **Test Suite**: Organized in `tests/` directory with comprehensive coverage
- **Memory Persistence**: Postgres delta snapshots (no tombstones initially)
- **Performance**: RAM pressure guards and model janitor for resource management

#### **N8N Workflow System**

- **Purpose**: Automation and integration workflows
- **Features**:
  - Document processing automation
  - Notification systems
  - Integration with external services
  - Error handling and recovery
  - **Backlog Scrubber Workflow**: Automated score calculation and updates
  - **AI-BACKLOG-META Integration**: Machine-readable command processing

#### **Dashboard System** (`dashboard/`)

- **Purpose**: Real-time monitoring and interaction
- **Features**:
  - System status monitoring
  - Document processing visualization
  - Interactive question answering
  - Performance metrics
  - Production monitoring integration
  - Health check endpoints (`/health`, `/ready`)
  - Security event tracking
  - System metrics collection

### 4. Supporting Infrastructure

#### **Database Layer**

- **PostgreSQL**: Primary data storage
- **PGVector**: Vector embeddings for similarity search
- **Schema**: Optimized for document processing and metadata

#### **File Processing System**

- **Watch Folder**: Monitors for new documents
- **Document Processor**: Extracts text and metadata
- **Tokenizer**: Breaks documents into searchable chunks

#### **Notification System**

- **Purpose**: Alert users to system events
- **Features**: Email, Slack, and custom integrations
- **Triggers**: Processing completion, errors, system status
- **Production monitoring**: Real-time security alerts and health notifications
- **Alert callbacks**: Configurable alert handlers for critical events

---

<!-- ANCHOR: testing -->
<a id="testing"></a>

## ğŸ§ª Testing Framework & Quality Assurance

### **Comprehensive Test Suite**

The system includes 8 comprehensive test files organized in `tests/` directory:

#### **Core System Tests**

- **`tests/test_rag_system.py`** (18KB) - RAG system functionality
- **`tests/test_enhanced_rag_system.py`** (19KB) - Enhanced RAG with DSPy
- **`tests/test_vector_store.py`** (15KB) - Vector database operations
- **`tests/test_document_processor.py`** (12KB) - Document processing pipeline

#### **Utility Tests**

- **`tests/test_metadata_extractor.py`** (12KB) - Metadata extraction
- **`tests/test_tokenizer.py`** (9.5KB) - Text processing and chunking
- **`tests/test_logger.py`** (6.7KB) - Logging and monitoring

#### **Integration Tests**

- **`tests/test_watch_folder.py`** (22KB) - File watching system

### **Test Organization**

- **`tests/` Directory**: All test files organized in dedicated subfolder
- **`tests/400_project-overview.md`**: Comprehensive documentation for running tests
- **`run_tests.sh`**: Convenient test runner script with multiple options
- **Test Categories**: Unit tests, integration tests, and system tests

### **Testing Methodology**

- **Unit Tests**: Individual component testing with mocks
- **Integration Tests**: Component interaction testing
- **System Tests**: End-to-end workflow validation
- **Performance Tests**: Load and stress testing
- **Security Tests**: Vulnerability and validation testing

### **Quality Gates**

- **Code Coverage**: Minimum 80% coverage requirement
- **Performance Benchmarks**: Response time and throughput validation
- **Security Validation**: Input validation and access control testing
- **Documentation**: Comprehensive documentation requirements

---

## ğŸ”§ Component Deep Dives

### **DSPy RAG System Architecture**

#### **Enhanced RAG System** (`src/dspy_modules/enhanced_rag_system.py`)

- **DSPy Integration**: Declarative programming for AI reasoning
- **Multi-Modal Processing**: Text, metadata, and structured data
- **Context Management**: Intelligent context selection and management
- **Response Generation**: High-quality, contextually relevant responses

#### **Document Processor** (`src/dspy_modules/document_processor.py`)

- **Multi-Format Support**: PDF, DOC, TXT, CSV, and more
- **Metadata Extraction**: Automatic categorization and tagging
- **Content Chunking**: Intelligent text segmentation
- **Quality Validation**: Content quality and completeness checks

#### **Vector Store** (`src/dspy_modules/vector_store.py`)

- **PostgreSQL + PGVector**: Scalable vector storage
- **Similarity Search**: Efficient semantic search capabilities
- **Index Management**: Automatic indexing and optimization
- **Query Optimization**: Fast retrieval with relevance ranking

### **Enhanced Metadata System**

#### **Metadata Extractor** (`src/utils/metadata_extractor.py`)

- **Automatic Categorization**: 9 main categories with smart detection
- **Priority Assignment**: High/Medium/Low based on content analysis
- **Content Type Detection**: Structured data, documents, text, images
- **Size Classification**: Small/Medium/Large file categorization
- **Version Detection**: Automatic version number extraction
- **Date Extraction**: Pattern-based date identification

#### **Categorization System**

| Category | Keywords | Priority | Use Case |
|----------|----------|----------|----------|
| **Pricing & Billing** | pricing, cost, billing | High | Financial documents |
| **Legal & Contracts** | contract, legal, terms | High | Legal compliance |
| **Marketing & Campaigns** | marketing, campaign, ad | Medium | Marketing materials |
| **Client & Customer Data** | client, customer, user | Medium | Customer information |
| **Reports & Analytics** | report, analytics, data | Medium | Business intelligence |
| **Technical & Code** | source, code, script | Medium | Development files |
| **Testing & Samples** | test, sample, example | Low | Development testing |
| **Documentation & Guides** | manual, guide, help | Medium | User documentation |
| **Financial Records** | invoice, receipt, payment | High | Financial tracking |

### **Dashboard Monitoring System**

#### **Real-Time Features**

- **Live Statistics**: Processing stats, category breakdowns, file analytics
- **Interactive Filtering**: Search by filename, category, tags, priority
- **Document Cards**: Rich visual representation with metadata badges
- **Modal Views**: Detailed metadata inspection for each document
- **System Health**: Real-time status monitoring and alerts

#### **Advanced Analytics**

- **Processing Statistics**: Total documents, completion rates, error tracking
- **Category Breakdown**: Visual representation of document distribution
- **File Type Analysis**: Breakdown by extension and content type
- **Size Statistics**: Average, largest, smallest file sizes
- **Recent Activity**: Documents added in last 24 hours

#### **API Endpoints**

- **`GET /api/documents`** - JSON list of all documents
- **`GET /api/stats`** - Processing statistics
- **`GET /api/metadata/<filename>`** - Metadata for specific document
- **`GET /health`** - System health check

### **Notification System**

#### **Multi-Channel Alerts**

- **Email Notifications**: Processing completion, errors, system status
- **Slack Integration**: Real-time alerts and status updates
- **Custom Webhooks**: Integration with external systems
- **In-App Notifications**: Dashboard-based alert system

#### **Alert Triggers**

- **Processing Events**: Document completion, failures, errors
- **System Events**: Health checks, performance issues, capacity warnings
- **User Events**: Manual triggers, scheduled reports, status updates
- **Error Events**: Exception handling, recovery attempts, failure notifications

---

<!-- ANCHOR: deployment -->
<a id="deployment"></a>

## âš™ï¸ Configuration and Setup

### **Database Setup**

#### **PostgreSQL Configuration**
```bash

# Install PostgreSQL and PGVector

sudo apt-get install postgresql postgresql-contrib
sudo apt-get install postgresql-14-pgvector  # For Ubuntu 22.04

# Create database and user

sudo -u postgres createdb ai_agency
sudo -u postgres createuser danieljacobs
sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE ai_agency TO danieljacobs;"
```text

#### **Database Schema**
```sql
-- Documents table
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    file_type VARCHAR(50),
    file_size BIGINT,
    chunk_count INTEGER DEFAULT 0,
    status VARCHAR(50) DEFAULT 'pending',
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Document chunks table
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id),
    chunk_text TEXT NOT NULL,
    chunk_embedding vector(1536),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Query logs table
CREATE TABLE query_logs (
    id SERIAL PRIMARY KEY,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    response_time FLOAT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```text

### **Environment Setup**

#### **Python Environment**
```bash

# Create virtual environment

python3 -m venv venv
source venv/bin/activate

# Install dependencies

pip install -r requirements-dspy.txt
pip install -r dashboard/requirements.txt
```text

#### **System Dependencies**
```bash

# Install system packages

sudo apt-get update
sudo apt-get install -y python3-pip python3-venv postgresql postgresql-contrib

# Install Python packages

pip install flask psycopg2-binary dspy-ai transformers torch
```text

### **Deployment Procedures**

#### **Development Setup**
```bash

# Clone repository

git clone https://github.com/TheMonk2121/ai-dev-tasks.git
cd ai-dev-tasks

# Setup DSPy system

cd dspy-rag-system
./setup_dspy.sh

# Start dashboard

cd ../dashboard
./start_dashboard.sh
```text

#### **Production Deployment**
```bash

# Setup production environment

sudo apt-get install nginx supervisor

# Configure nginx for dashboard

sudo nano /etc/nginx/sites-available/ai-dashboard

# Setup supervisor for background processes

sudo nano /etc/supervisor/conf.d/ai-processes.conf

# Start services

sudo systemctl restart nginx
sudo supervisorctl reread
sudo supervisorctl update
```text

### **System Requirements**

#### **Minimum Requirements**

- **CPU**: 4 cores (8+ recommended)
- **RAM**: 8GB (16GB+ recommended)
- **Storage**: 50GB SSD
- **OS**: Ubuntu 22.04 LTS or macOS 12+

#### **Recommended Requirements**

- **CPU**: 8+ cores
- **RAM**: 32GB
- **Storage**: 200GB NVMe SSD
- **GPU**: NVIDIA GPU with 8GB+ VRAM (for AI processing)

---

## ğŸš€ Advanced Features

### **File Watching System**

#### **Real-Time Document Processing**

- **Watch Folder**: Monitors specified directories for new files
- **Automatic Processing**: Triggers processing pipeline on file detection
- **Multi-Format Support**: Handles PDF, DOC, TXT, CSV, and more
- **Error Recovery**: Automatic retry and error handling

#### **Processing Pipeline**
```python

# File watching workflow

1. File Detection â†’ Watch folder detects new file
2. Validation â†’ Check file format and size
3. Processing â†’ Extract text and metadata
4. Chunking â†’ Break into searchable chunks
5. Embedding â†’ Generate vector embeddings
6. Storage â†’ Save to PostgreSQL + PGVector
7. Notification â†’ Alert completion status

```text

### **Enhanced Metadata Extraction**

#### **Intelligent Categorization**

- **Pattern Recognition**: Filename and content pattern analysis
- **Keyword Detection**: Business-specific keyword identification
- **Context Analysis**: Content context and relationship detection
- **Priority Assignment**: Automatic priority based on content type

#### **Metadata Fields**
```json
{
  "category": "Pricing & Billing",
  "priority": "high",
  "tags": ["pricing", "financial", "confidential"],
  "content_type": "structured_data",
  "size_category": "medium",
  "version": "v2.1.0",
  "extracted_date": "2024-01-15",
  "processing_status": "completed"
}
```text

### **Cursor IDE Integration**

#### **Development Workflow**

- **PRD Creation**: Use `001_create-prd.md` in Cursor
- **Task Generation**: Use `002_generate-tasks.md` for implementation
- **Task Execution**: Use `003_process-task-list.md` for AI-driven development
- **State Management**: Automatic `.ai_state.json` handling

#### **AI Agent Configuration**
```json
{
  "customModels": [
    {
      "title": "Cursor Native AI Local",
      "model": "mistral",
      "baseURL": "http://localhost:11434/v1",
      "apiKey": ""
    }
  ],
  "defaultModel": "cursor-native-ai"
}
```text

### **Performance Optimization**

#### **Caching Strategies**

- **State Caching**: `.ai_state.json` for context persistence
- **Vector Caching**: Redis for frequently accessed embeddings
- **Result Caching**: Memoization for repeated queries
- **Connection Pooling**: Database connection optimization

#### **Scalability Features**

- **Horizontal Scaling**: Multiple processing nodes
- **Load Balancing**: Distributed processing across nodes
- **Queue Management**: Redis-based job queuing
- **Resource Monitoring**: Real-time resource usage tracking

---

<!-- ANCHOR: integration -->
<a id="integration"></a>

## ğŸ”§ Technical Implementation (Micro View)

### State Management
```json
{
  "last_commit": "abc123",
  "file_list": ["src/main.py", "tests/test_main.py"],
  "test_results": {"passed": 15, "failed": 0},
  "current_task": "T-5",
  "completed_tasks": ["T-1", "T-2", "T-3", "T-4"]
}
```text

### Task Template
```markdown

### T-<number> <Task Name>

**Priority**: Critical | High | Medium | Low
**Time**: <2-4 hours>
**Depends on**: [T-1, T-2] or "None"

**Do**:

1. <specific step 1>
2. <specific step 2>
3. <specific step 3>

**Done when**:

- <testable outcome 1>
- <testable outcome 2>
- <testable outcome 3>

**Auto-Advance**: yes | no
**ğŸ›‘ Pause After**: yes | no
**When Ready Prompt**: "<brief question for human review>"
```text

### Error Recovery Process

1. **Detection**: Task validation fails
2. **HotFix Generation**: Create structured fix task
3. **Implementation**: AI implements fix with regression test
4. **Retry**: Re-run original task validation
5. **Continue**: Resume normal execution

---

<!-- ANCHOR: migration -->
<a id="migration"></a>

## ğŸ¯ Use Cases & Applications

### 1. Feature Development

- **Input**: "I want to add user authentication"
- **Process**: PRD â†’ Tasks â†’ AI Implementation â†’ Deployment
- **Output**: Working authentication system

### 2. System Integration

- **Input**: "Connect our app to Slack notifications"
- **Process**: PRD â†’ Tasks â†’ AI Implementation â†’ Testing
- **Output**: Automated Slack integration

### 3. Document Processing

- **Input**: "Process PDFs and answer questions about them"
- **Process**: PRD â†’ Tasks â†’ AI Implementation â†’ RAG System
- **Output**: Intelligent document Q&A system

### 4. Workflow Automation

- **Input**: "Automate our customer onboarding process"
- **Process**: PRD â†’ Tasks â†’ AI Implementation â†’ N8N Workflows
- **Output**: Automated customer onboarding

---

<!-- ANCHOR: performance -->
<a id="performance"></a>

## ğŸš€ Getting Started

### For New Users

1. **Clone Repository**: `git clone https://github.com/TheMonk2121/ai-dev-tasks.git`
2. **Read README**: Understand the basic workflow
3. **Review Backlog**: Check `000_backlog.md` for high-impact features (see `100_backlog-guide.md` for usage)
4. **Start with PRD**: Use `001_create-prd.md` for your first feature
5. **Generate Tasks**: Use `002_generate-tasks.md` to create implementation plan
6. **Execute with AI**: Use `003_process-task-list.md` for AI-driven development
7. **Review Organization**: Check `200_naming-conventions.md` to understand file structure

### For Advanced Users

1. **Review Backlog**: Check `000_backlog.md` for systematic development planning (see `100_backlog-guide.md` for usage)
2. **Explore DSPy System**: Check `dspy-rag-system/` for document processing
3. **Review N8N Workflows**: Understand automation capabilities
4. **Customize Workflows**: Adapt templates for your specific needs
5. **Extend Functionality**: Add new AI agents or systems
6. **Setup Scoring System**: Configure n8n scrubber for automated prioritization
7. **Use AI-BACKLOG-META**: Leverage machine-readable commands for automation
8. **Review Naming Conventions**: Check `200_naming-conventions.md` for file organization

### For System Administrators

1. **Setup Infrastructure**: PostgreSQL, Python environment
2. **Configure AI Agents**: Cursor Native AI, Specialized Agents setup
3. **Deploy Dashboard**: Monitor system performance
4. **Setup Notifications**: Configure alert systems

---

## ğŸ” System Monitoring

### Key Metrics

- **Task Completion Rate**: Percentage of tasks completed successfully
- **Error Recovery Time**: Time from error detection to HotFix completion
- **Human Intervention Rate**: Frequency of required human checkpoints
- **System Performance**: Response times and resource usage

### Monitoring Tools

- **Dashboard**: Real-time system status
- **Logs**: Detailed execution tracking
- **Notifications**: Alert system for issues
- **State Files**: Progress tracking and context
- **Production Monitor**: Security events, health checks, system metrics
- **Health Endpoints**: Kubernetes-ready `/health` and `/ready` endpoints
- **OpenTelemetry**: Distributed tracing for production debugging
- **Database Resilience**: Connection pooling with health monitoring and retry logic

---

## ğŸ”® Future Enhancements

### Planned Features

- **Multi-Agent Coordination**: Enhanced collaboration between AI agents
- **Advanced Error Recovery**: Predictive error detection and prevention
- **Performance Optimization**: Improved state management and caching
- **Integration Expansion**: More external service connections
- **Enhanced Scoring**: Machine learning-based score optimization
- **Automated Backlog Management**: Self-organizing backlog with AI agents

### Research Areas

- **Agent Specialization**: Domain-specific AI agents
- **Learning Systems**: Continuous improvement from execution patterns
- **Automated Testing**: Enhanced test generation and validation
- **Deployment Automation**: Streamlined production deployment

---

## ğŸ“š **Documentation References**

### **Core Architecture**

- **`docs/ARCHITECTURE.md`**: Comprehensive v0.3.1 architecture documentation
- **`docs/CONFIG_REFERENCE.md`**: Complete configuration reference and schema

### **Implementation Guides**

- **`201_model-configuration.md`**: AI model setup and configuration
- **`400_file-analysis-guide.md`**: Systematic file analysis methodology
- **`103_yi-coder-integration.md`**: External model integration guide (legacy)

### **System Documentation**

- **`104_dspy-development-context.md`**: DSPy development context and status
- **`200_naming-conventions.md`**: File organization and naming conventions

---

This system represents a comprehensive approach to AI-assisted development, combining structured workflows with intelligent automation to create a powerful development ecosystem. 
