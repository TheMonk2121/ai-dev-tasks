# Retrieval Configuration for RAG System
# Defines candidate generation defaults and fusion parameters

# Candidate Generation Limits
candidates:
  # Number of documents to retrieve from each method before fusion
  bm25_limit: 100 # Lexical retrieval candidates
  vector_limit: 100 # Semantic retrieval candidates

  # Post-fusion limits
  final_limit: 50 # Maximum documents after RRF fusion
  min_candidates: 10 # Minimum candidates required for valid retrieval

# Weighted RRF Fusion Parameters
fusion:
  # RRF smoothing constant (higher values reduce impact of lower ranks)
  k: 60

  # Fusion weights (must sum to 1.0, will be normalized if not)
  lambda_lex: 0.6 # Weight for lexical (BM25) results
  lambda_sem: 0.4 # Weight for semantic (vector) results

  # Alternative weight profiles for different use cases
  profiles:
    balanced: # Equal weighting
      lambda_lex: 0.5
      lambda_sem: 0.5

    lexical_heavy: # Favor exact term matches
      lambda_lex: 0.8
      lambda_sem: 0.2

    semantic_heavy: # Favor conceptual similarity
      lambda_lex: 0.3
      lambda_sem: 0.7

# Pre-filtering (applied before fusion)
prefilter:
  # Minimum score thresholds (documents below threshold are excluded)
  min_bm25_score: 0.1 # Minimum BM25 relevance score
  min_vector_score: 0.7 # Minimum cosine similarity (recall-friendly)

  # Document length filters
  min_doc_length: 50 # Minimum characters in document
  max_doc_length: 8000 # Maximum characters (for context window management)

  # Diversity settings
  enable_diversity: true # Remove near-duplicate documents
  diversity_threshold: 0.9 # Cosine similarity threshold for deduplication

# Performance and Caching
performance:
  # Enable result caching
  enable_cache: true
  cache_ttl_seconds: 3600 # 1 hour cache TTL

  # Parallel processing
  max_workers: 4 # Concurrent retrieval threads
  timeout_seconds: 30 # Per-query timeout

  # Memory management
  max_cache_size: 1000 # Maximum cached queries

# Reranking (cross-encoder + fallback)
rerank:
  enabled: true
  alpha: 0.7 # Weight of rerank vs fused score
  final_top_n: 8 # Final selection count after rerank
  method: cross_encoder # cross_encoder | heuristic

  # Cross-encoder settings
  cross_encoder:
    model_name: "BAAI/bge-reranker-base" # BGE reranker baseline
    onnx_path: "models/reranker.onnx" # ONNX-INT8 export path
    micro_batch_size: 32 # Micro-batch pairs for efficiency
    timeout_ms: 400 # Per-request budget
    max_timeout_ms: 600 # Hard timeout before fallback
    fallback_to_heuristic: true # Fallback on timeout/error
    workers: 3 # Max concurrent reranker workers

  # Windowing (before rerank)
  windowing:
    enabled: true
    window_size_tokens: 150 # 120-180 token windows
    overlap_pct: 33 # 30-40% overlap
    preserve_doc_boundaries: true # Don't cross document boundaries

  # Near-duplicate suppression
  dedup:
    enabled: true
    method: cosine # cosine | minhash
    threshold: 0.9 # Similarity threshold for dedup
    before_rerank: true # Apply deduplication before reranking

# Packing (context assembly)
packing:
  mmr_lambda: 0.7 # MMR diversity vs relevance balance (0=diverse, 1=relevant)
  context_cap_tokens: 2000 # Maximum context size in characters
  max_snippets: 3 # Maximum snippets per document
  evidence_first: true # Prioritize evidence over metadata

# Intent routing & policies
intent_routing:
  enabled: true
  # Simple rule-based intents with thresholds
  policies:
    - name: config_query
      when_any:
        - contains:
            [".yml", ".yaml", "pyproject.toml", "Makefile", ".github/workflows"]
        - regex: "(?i)config|configuration|settings"
      action:
        rerank_alpha: 0.5 # more weight to fused
        fusion_profile: lexical_heavy
        final_top_n: 10

    - name: conceptual_query
      when_any:
        - regex: "(?i)explain|why|how does|architecture|design"
      action:
        rerank_alpha: 0.8 # more weight to reranker
        fusion_profile: semantic_heavy
        final_top_n: 8

    - name: technical_code
      when_any:
        - regex: "(?i)(def |class |import |SELECT |INSERT |`|::|->)"
      action:
        rerank_alpha: 0.75
        fusion_profile: balanced
        final_top_n: 8

# Tuning & Quality Gates
tuning:
  # Performance targets (aligned with B-1059 success criteria)
  targets:
    recall_at_20: 0.35 # Minimum recall target (currently 0.099)
    precision_at_k: 0.12 # Maintain precision (no regression)
    f1_score: 0.22 # Minimum F1 target (currently 0.112)
    faithfulness: 0.60 # Global faithfulness minimum

  # Evaluation thresholds for quality gates
  quality_gates:
    # Soft gates (warn but don't fail)
    soft:
      recall_at_20: 0.25 # Warning threshold
      f1_score: 0.15 # Warning threshold
      faithfulness: 0.50 # Warning threshold

    # Hard gates (fail pipeline if below)
    hard:
      recall_at_20: 0.20 # Absolute minimum
      f1_score: 0.10 # Absolute minimum
      faithfulness: 0.40 # Absolute minimum

  # Hyperparameter search spaces
  search_spaces:
    fusion:
      lambda_lex: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
      lambda_sem: [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]
      k: [30, 45, 60, 75, 90]

    rerank:
      alpha: [0.5, 0.6, 0.7, 0.8, 0.9]
      final_top_n: [6, 8, 10, 12, 15]

    prefilter:
      min_bm25_score: [0.05, 0.1, 0.15, 0.2]
      min_vector_score: [0.6, 0.65, 0.7, 0.75, 0.8]
      diversity_threshold: [0.85, 0.9, 0.95]

# Phase 0: Evaluation, Telemetry & Canary
evaluation:
  # Golden evaluation slices
  golden_sets:
    base_path: "configs/eval/golden/"
    slices:
      - name: "novice_vs_expert"
        path: "novice_expert_queries.jsonl"
      - name: "single_vs_multi_hop"
        path: "hop_complexity_queries.jsonl"
      - name: "structured_vs_unstructured"
        path: "data_type_queries.jsonl"
      - name: "freshness_sensitive_vs_evergreen"
        path: "temporal_queries.jsonl"

  # Metrics to compute
  metrics:
    enabled: ["ndcg_10", "coverage", "exact_match", "span_support", "f1", "ece"]
    temperature_scaling: true # Calibrate confidence via temp scaling
    confidence_threshold: 0.6 # Abstain threshold after calibration

# Telemetry & Observability
telemetry:
  enabled: true
  per_request_logging: true # Log full query → answer pipeline
  log_path: "metrics/logs/requests.jsonl"
  log_fields:
    [
      "query",
      "candidates",
      "fusion_ranks",
      "rerank_scores",
      "selected_spans",
      "answer",
      "confidence",
      "user_action",
    ]

  # Per-stage timing
  stage_timing: true
  stages: ["bm25", "vector", "fusion", "prefilter", "rerank", "generate"]
  timing_percentiles: [50, 95] # p50 and p95 for TTFT

# Canary & A/B Testing
canary:
  enabled: false # Feature flag for canary deployment
  sample_pct: 10 # Percentage of traffic to canary
  tag_requests: true # Tag requests for before/after analysis
  store_ranks: true # Store before/after ranks for hard-negative mining
  comparison_metrics: ["ndcg_10", "latency_p95", "user_satisfaction"]

# Advanced concurrency & resilience
resilience:
  # Singleflight deduplication
  singleflight:
    enabled: true
    ttl_seconds: 30 # Cache identical queries for 30s

  # Graceful degradation
  fallback:
    bm25_only_on_timeout: true # Fall back to BM25-only on vector/rerank timeout
    max_retries: 1 # Retry failed components once
    circuit_breaker: true # Open circuit on repeated failures

# Phase 2: Multi-Hop & Answer Planning
multihop:
  enabled: true
  
  # Data-driven gating thresholds
  max_hops: 2 # Hard limit on hop count
  token_budget: 512 # Maximum additional tokens for follow-up queries
  coverage_threshold: 0.7 # τ₁ for sub-claims support (fraction with ≥1 high-score window)
  concentration_threshold: 0.6 # Low dispersion threshold (evidence not scattered)
  novelty_threshold: 0.8 # Cosine similarity threshold for near-duplicate sub-queries
  min_evidence_score: 0.3 # Minimum reranker score for evidence support
  
  # Mid-generation callbacks
  midgen_callbacks:
    enabled: true
    uncertainty_threshold: 0.4 # Trigger callback when confidence < threshold
    max_followup_queries: 2 # Limit follow-up queries per callback
    
  # Query complexity assessment
  complexity:
    word_count_threshold: 15 # Words needed to consider multi-hop
    multihop_indicators: ["and", "or", "but", "compare", "versus", "why", "how"]
    complexity_score_threshold: 2 # Minimum indicators to trigger multi-hop
    
  # Performance limits
  performance:
    max_subqueries_per_hop: 3 # Limit sub-questions per hop
    retrieval_timeout_ms: 2000 # Timeout per sub-question retrieval
    synthesis_timeout_ms: 1000 # Timeout for answer synthesis
