# Cursor AI Memory Context Rules

## ðŸ§  Memory Context System

This project uses a sophisticated memory context system to maintain state across Cursor AI sessions.
The key file is `100_cursor-memory-context.md` which provides instant context about the AI development ecosystem.

### **ðŸš¨ AUTOMATIC MEMORY REHYDRATION - START EVERY CHAT WITH THIS**

**At the beginning of every new chat, automatically run this command to prime the model with core documentation:**

```bash
python3 scripts/prime_cursor_chat.py planner "current project status and core documentation"
```

**This script automatically formats the output for easy copying into Cursor chat.**

**Alternative manual methods:**
```bash
# Python implementation
python3 scripts/cursor_memory_rehydrate.py planner "current project status and core documentation"

# Go implementation (faster)
cd dspy-rag-system/src/utils && ./memory_rehydration_cli --query "current project status and core documentation"
```
**Then copy the entire bundle output into the chat as the first message.**

**This ensures the AI has immediate access to:**
- Current project status and priorities
- System architecture and components
- Available workflows and commands
- Development guidelines and best practices
- Backlog items and dependencies

### **ðŸš¨ PRIORITY: Use Database-Based Memory Rehydration**

**BEFORE reading any files directly, try to use the database-based memory rehydration system:**

1. **Run the memory rehydrator**: Choose Python or Go implementation
2. **Copy the bundle output** into your conversation for context
3. **Only fall back to file reading** if the database is unavailable

**Available roles:**
- `planner` - For strategic planning and prioritization
- `implementer` - For code implementation and technical work
- `researcher` - For research and analysis tasks

**Example usage:**
```bash
# Python implementation
python3 scripts/cursor_memory_rehydrate.py planner "current project priorities"
python3 scripts/cursor_memory_rehydrate.py implementer "DSPy integration task"

# Go implementation (faster)
cd dspy-rag-system/src/utils && ./memory_rehydration_cli --query "current project priorities"
cd dspy-rag-system/src/utils && ./memory_rehydration_cli --query "DSPy integration task"
```

### **When Starting a New Session**

1. **Always read `100_memory/100_cursor-memory-context.md` first** - this gives you the current project state
2. **Check `000_core/000_backlog.md`** for current priorities and dependencies
3. **Review `400_guides/400_system-overview.md`** if you need deeper technical context
4. **Use existing workflows** (`000_core/001_create-prd.md`, `000_core/002_generate-tasks.md`, `000_core/003_process-task-list.md`)

### **Memory Context Hierarchy (Reading Order)**

**HIGH Priority (Read First):**

- `100_memory/100_cursor-memory-context.md` - Memory scaffold and current state
- `400_guides/400_system-overview.md` - Technical architecture
- `000_core/000_backlog.md` - Current priorities and roadmap
- `400_guides/400_project-overview.md` - Project overview and workflow

**MEDIUM Priority (Read as Needed):**

- `000_core/001_create-prd.md` - PRD creation workflow
- `000_core/002_generate-tasks.md` - Task generation workflow
- `000_core/003_process-task-list.md` - AI execution workflow
- `100_memory/104_dspy-development-context.md` - Deep technical context

**LOW Priority (Read for Specific Tasks):**

- `100_memory/100_backlog-guide.md` - Backlog management

### Exclusions (Policy)

- Ignore `600_archives/**` and `docs/legacy/**` when reading or linking
- Route legacy integrations/model-specific guides to `600_archives/**`
- After archiving or major doc moves, run `python scripts/update_cursor_memory.py`

### **When Working on Features**

1. **Follow the development guidelines** in `100_memory/100_cursor-memory-context.md`
2. **Use the existing file organization** from `400_guides/400_context-priority-guide.md`
3. **Update completion summaries** when finishing major features
4. **Run `python scripts/update_cursor_memory.py`** to keep memory context current
5. **Code reuse**: Before writing new code, apply the find-or-build heuristic (search-before-write, 70% reuse, tests-first)
   in `400_file-analysis-guide.md`

### **When Adding New Features**

1. **Add to backlog** with proper scoring (see `100_memory/100_backlog-guide.md`)
2. **Create PRD** using `000_core/001_create-prd.md` workflow
3. **Generate tasks** using `000_core/002_generate-tasks.md` workflow
4. **Execute** using `000_core/003_process-task-list.md` workflow

### **cSpell Automation Pattern**

**When user requests cSpell word addition or mentions "missing definitions":**
- **Role**: Use `coder` role (handles development tooling and configuration)
- **Script**: Use `python3 scripts/cspell_automation.py "word1 word2 word3"`
- **Pattern**: This is a frequent, deterministic task that should be automated
- **Memory**: See `100_memory/105_cspell-automation-memory.md` for full pattern
- **Integration**: cSpell automation is part of coder role responsibilities

### **Key Files for Context**

- **Memory Context**: `100_memory/100_cursor-memory-context.md` (current state)
- **System Overview**: `400_guides/400_system-overview.md` (technical architecture)
- **Backlog**: `000_core/000_backlog.md` (priorities and status)
- **Setup**: `200_setup/202_setup-requirements.md` (environment setup)

### **Current Development Focus**

- **B-002**: Advanced Error Recovery & Prevention (5 points) âœ… completed
- **B-011**: Cursor Native AI + Specialized Agents Integration (5 points)
- **Infrastructure**: v0.3.1-rc3 Core Hardening âœ… completed

### **System Architecture**

- **AI Models**: Cursor Native AI (foundation), Specialized Agents (enhancements)
- **Framework**: DSPy with PostgreSQL vector store
- **Automation**: n8n workflows for backlog management
- **Monitoring**: Real-time mission dashboard
- **Security**: Comprehensive input validation and prompt sanitization

### **Development Workflow**

1. **Backlog Selection** â†’ Choose from `000_core/000_backlog.md` (B-001, B-002, etc.)
2. **PRD Creation** â†’ Use `000_core/001_create-prd.md` workflow
3. **Task Generation** â†’ Use `000_core/002_generate-tasks.md` workflow
4. **AI Execution** â†’ Use `000_core/003_process-task-list.md` workflow
5. **State Management** â†’ `.ai_state.json` for context persistence

### **When Debugging Issues**

1. **Check `dspy-rag-system/docs/CURRENT_STATUS.md`** for system health
2. **Review error logs** in `dspy-rag-system/src/utils/logger.py`
3. **Use retry wrapper** from `dspy-rag-system/src/utils/retry_wrapper.py`
4. **Check security validation** from `dspy-rag-system/src/utils/prompt_sanitizer.py`

### **Key Commands**

- **Start Dashboard**: `./dspy-rag-system/start_mission_dashboard.sh`
- **Run Tests**: `./dspy-rag-system/run_tests.sh`
- **Quick Start**: `./dspy-rag-system/quick_start.sh`
- **Update Memory**: `python scripts/update_cursor_memory.py`

### **File Organization**

- **Essential**: `400_guides/400_project-overview.md`, `400_guides/400_system-overview.md`, `000_core/000_backlog.md`
- **Implementation**: `100_memory/104_dspy-development-context.md`, `200_setup/202_setup-requirements.md`
- **Domain**: `100_memory/100_backlog-guide.md`

### **Memory State Updates**

- **When to update**: After completing backlog items, changing focus, adding features
- **How to update**: Run `python scripts/update_cursor_memory.py`
- **What gets updated**: Priorities, completed items, system status, timestamps

Remember: This is a sophisticated AI development ecosystem. Always check the memory context first,
then dive deeper into specific files as needed
