# Cursor AI Memory Context Rules

## ðŸ§  Memory Context System

This project uses a sophisticated memory context system to maintain state across Cursor AI sessions.
The key file is `100_cursor-memory-context.md` which provides instant context about the AI development ecosystem.

### **ðŸš¨ AUTOMATIC MEMORY REHYDRATION - START EVERY CHAT WITH THIS**

**At the beginning of every new chat, automatically run this command to prime the model with core documentation:**

```bash
./scripts/memory_up.sh
```

**This script automatically fires up all memory systems and formats the output for easy copying into Cursor chat.**

**Alternative methods (if needed):**
```bash
# With custom query and role
./scripts/memory_up.sh -q "current project status and core documentation" -r planner

# For specific roles
./scripts/memory_up.sh -r coder "DSPy integration task"
./scripts/memory_up.sh -r implementer "database optimization"
./scripts/memory_up.sh -r researcher "performance analysis"

# JSON output for programmatic access
./scripts/memory_up.sh -f json
```
**Then copy the entire bundle output into the chat as the first message.**

**This ensures the AI has immediate access to:**
- Current project status and priorities
- System architecture and components
- Available workflows and commands
- Development guidelines and best practices
- Backlog items and dependencies
- Role-specific context (planner, implementer, researcher, coder)
- System status and recent changes

### **ðŸš¨ PRIORITY: Use Database-Based Memory Rehydration**

**BEFORE reading any files directly, try to use the database-based memory rehydration system:**

1. **Run the memory rehydrator**: Choose Python or Go implementation
2. **Copy the bundle output** into your conversation for context
3. **Only fall back to file reading** if the database is unavailable

**Available roles:**
- `planner` - For strategic planning and prioritization
- `implementer` - For code implementation and technical work
- `researcher` - For research and analysis tasks

**Example usage:**
```bash
# Python implementation
python3 scripts/cursor_memory_rehydrate.py planner "current project priorities"
python3 scripts/cursor_memory_rehydrate.py implementer "DSPy integration task"

# Go implementation (faster)
cd dspy-rag-system/src/utils && ./memory_rehydration_cli --query "current project priorities"
cd dspy-rag-system/src/utils && ./memory_rehydration_cli --query "DSPy integration task"
```

### **When Starting a New Session**

1. **Always read `100_memory/100_cursor-memory-context.md` first** - this gives you the current project state
2. **Check `000_core/000_backlog.md`** for current priorities and dependencies
3. **Review `400_guides/400_system-overview.md`** if you need deeper technical context
4. **Use existing workflows** (`000_core/001_create-prd.md`, `000_core/002_generate-tasks.md`, `000_core/003_process-task-list.md`)

### **Memory Context Hierarchy (Reading Order)**

**HIGH Priority (Read First):**

- `100_memory/100_cursor-memory-context.md` - Memory scaffold and current state
- `400_guides/400_system-overview.md` - Technical architecture
- `000_core/000_backlog.md` - Current priorities and roadmap
- `400_guides/400_project-overview.md` - Project overview and workflow

**MEDIUM Priority (Read as Needed):**

- `000_core/001_create-prd.md` - PRD creation workflow
- `000_core/002_generate-tasks.md` - Task generation workflow
- `000_core/003_process-task-list.md` - AI execution workflow
- `100_memory/104_dspy-development-context.md` - Deep technical context

**LOW Priority (Read for Specific Tasks):**

- `100_memory/100_backlog-guide.md` - Backlog management

### Exclusions (Policy)

- Ignore `600_archives/**` and `docs/legacy/**` when reading or linking
- Route legacy integrations/model-specific guides to `600_archives/**`
- After archiving or major doc moves, run `python scripts/update_cursor_memory.py`

### **When Working on Features**

1. **Follow the development guidelines** in `100_memory/100_cursor-memory-context.md`
2. **Use the existing file organization** from `400_guides/400_context-priority-guide.md`
3. **Update completion summaries** when finishing major features
4. **Run `python scripts/update_cursor_memory.py`** to keep memory context current
5. **Code reuse**: Before writing new code, apply the find-or-build heuristic (search-before-write, 70% reuse, tests-first)
   in `400_file-analysis-guide.md`

### **When Adding New Features**

1. **Add to backlog** with proper scoring (see `100_memory/100_backlog-guide.md`)
2. **Create PRD** using `000_core/001_create-prd.md` workflow
3. **Generate tasks** using `000_core/002_generate-tasks.md`
