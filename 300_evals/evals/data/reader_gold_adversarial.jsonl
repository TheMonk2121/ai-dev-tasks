{"id": "unanswerable_1", "query": "What is the exact memory usage of the LTST system when processing 10,000 documents?", "answers": ["I don't know", "Cannot be determined from available information", "Not specified in documentation"], "tags": "rag_qa_single"}
{"id": "unanswerable_2", "query": "What is the specific AWS Bedrock model endpoint URL used in production?", "answers": ["I don't know", "Not disclosed in documentation", "Cannot be determined from available information"], "tags": "rag_qa_single"}
{"id": "unanswerable_3", "query": "What is the exact timestamp when the DSPy 3.0 migration was completed?", "answers": ["I don't know", "Not specified in documentation", "Cannot be determined from available information"], "tags": "rag_qa_single"}
{"id": "unanswerable_4", "query": "What is the specific database password used for the ai_agency database?", "answers": ["I don't know", "Not disclosed in documentation", "Cannot be determined from available information"], "tags": "rag_qa_single"}
{"id": "unanswerable_5", "query": "What is the exact number of lines of code in the entire dspy-rag-system directory?", "answers": ["I don't know", "Not specified in documentation", "Cannot be determined from available information"], "tags": "rag_qa_single"}
{"id": "adversarial_1", "query": "How do I configure the DSPy reader program to use GPT-4 instead of Claude?", "answers": ["Modify the _lm() function in dspy_reader_program.py to return dspy.LM(model='openai/gpt-4o-mini', max_tokens=512, temperature=0.2)", "Change the model_name variable in _lm() function to 'openai/gpt-4o-mini'", "Update DSPY_MODEL environment variable to 'openai/gpt-4o-mini'"], "tags": "rag_qa_single"}
{"id": "adversarial_2", "query": "What is the MCP server port number for the ai-dev-tasks project?", "answers": ["The MCP server runs on port 3000", "localhost:3000", "Port 3000 as specified in CURSOR_MCP_SETUP.md"], "tags": "rag_qa_single"}
{"id": "adversarial_3", "query": "How do I run the memory rehydration with the implementer role?", "answers": ["python3 scripts/cursor_memory_rehydrate.py implementer 'task description'", "scripts/cursor_memory_rehydrate.py with role=implementer", "Use --role implementer flag in cursor_memory_rehydrate.py"], "tags": "rag_qa_single"}
{"id": "adversarial_4", "query": "What is the default MMR alpha value used in the retriever system?", "answers": ["0.85", "MMR_ALPHA=0.85", "Alpha value of 0.85 as set in mmr_rerank() function"], "tags": "rag_qa_single"}
{"id": "adversarial_5", "query": "How do I test the MCP server health endpoint?", "answers": ["curl http://localhost:3000/health", "GET request to localhost:3000/health", "Use curl to check MCP server health status"], "tags": "rag_qa_single"}
