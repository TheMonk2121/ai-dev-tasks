// Test script for LM Studio integration and Yi-Coder model
const axios = require('axios');

console.log('üß™ Testing LM Studio Integration and Yi-Coder Model...');

const OLLAMA_URL = 'http://localhost:11434';
const MODEL_NAME = 'mistral';

// Test 1: Check if LM Studio server is running
async function testServerConnection() {
    console.log('‚úÖ Test 1: Ollama Server Connection');
    try {
        const response = await axios.get(`${OLLAMA_URL}/api/tags`, {
            timeout: 5000
        });
        console.log('   - ‚úÖ Ollama server is running');
        console.log('   - üìã Available models:', response.data.models?.length || 0);
        return true;
    } catch (error) {
        console.log('   - ‚ùå Ollama server not responding');
        console.log('   - üí° Make sure Ollama is running: ollama serve');
        return false;
    }
}

// Test 2: Check if Mistral model is loaded
async function testModelAvailability() {
    console.log('‚úÖ Test 2: Mistral Model Availability');
    try {
        const response = await axios.get(`${OLLAMA_URL}/api/tags`, {
            timeout: 5000
        });
        
        const models = response.data.models || [];
        const mistralModel = models.find(model => 
            model.name.toLowerCase().includes('mistral')
        );
        
        if (mistralModel) {
            console.log('   - ‚úÖ Mistral model found:', mistralModel.name);
            return true;
        } else {
            console.log('   - ‚ùå Mistral model not found');
            console.log('   - üí° Available models:', models.map(m => m.name).join(', '));
            console.log('   - üí° Load Mistral model: ollama pull mistral');
            return false;
        }
    } catch (error) {
        console.log('   - ‚ùå Failed to check model availability');
        return false;
    }
}

// Test 3: Test basic code generation
async function testCodeGeneration() {
    console.log('‚úÖ Test 3: Basic Code Generation');
    try {
        const testPrompt = {
            model: MODEL_NAME,
            messages: [
                {
                    role: 'user',
                    content: 'Write a simple Python function to calculate the sum of two numbers'
                }
            ],
            temperature: 0.7,
            max_tokens: 200,
            stream: false
        };
        
        const startTime = Date.now();
        const response = await axios.post(`${OLLAMA_URL}/api/chat`, testPrompt, {
            timeout: 30000, // 30 second timeout
            headers: {
                'Content-Type': 'application/json'
            }
        });
        const endTime = Date.now();
        const responseTime = endTime - startTime;
        
        const content = response.data.choices?.[0]?.message?.content;
        if (content) {
            console.log('   - ‚úÖ Code generation successful');
            console.log('   - ‚è±Ô∏è  Response time:', responseTime + 'ms');
            console.log('   - üìù Generated code preview:', content.substring(0, 100) + '...');
            
            // Check if response time meets requirements
            if (responseTime < 2000) {
                console.log('   - ‚úÖ Response time under 2 seconds');
            } else {
                console.log('   - ‚ö†Ô∏è  Response time over 2 seconds:', responseTime + 'ms');
            }
            
            return true;
        } else {
            console.log('   - ‚ùå No content in response');
            return false;
        }
    } catch (error) {
        console.log('   - ‚ùå Code generation failed:', error.message);
        return false;
    }
}

// Test 4: Test code completion
async function testCodeCompletion() {
    console.log('‚úÖ Test 4: Code Completion');
    try {
        const testPrompt = {
            model: MODEL_NAME,
            messages: [
                {
                    role: 'user',
                    content: 'Complete this Python function:\n\ndef calculate_area(radius):\n    # Calculate the area of a circle'
                }
            ],
            temperature: 0.7,
            max_tokens: 150,
            stream: false
        };
        
        const response = await axios.post(`${OLLAMA_URL}/api/chat`, testPrompt, {
            timeout: 30000,
            headers: {
                'Content-Type': 'application/json'
            }
        });
        
        const content = response.data.choices?.[0]?.message?.content;
        if (content && content.includes('return')) {
            console.log('   - ‚úÖ Code completion successful');
            console.log('   - üìù Completion preview:', content.substring(0, 100) + '...');
            return true;
        } else {
            console.log('   - ‚ùå Code completion failed or incomplete');
            return false;
        }
    } catch (error) {
        console.log('   - ‚ùå Code completion failed:', error.message);
        return false;
    }
}

// Test 5: Test error handling
async function testErrorHandling() {
    console.log('‚úÖ Test 5: Error Handling');
    try {
        // Test with invalid model name
        const testPrompt = {
            model: 'Invalid-Model-Name',
            messages: [
                {
                    role: 'user',
                    content: 'Hello'
                }
            ],
            temperature: 0.7,
            max_tokens: 50,
            stream: false
        };
        
        await axios.post(`${OLLAMA_URL}/api/chat`, testPrompt, {
            timeout: 10000,
            headers: {
                'Content-Type': 'application/json'
            }
        });
        
        console.log('   - ‚ùå Should have failed with invalid model');
        return false;
    } catch (error) {
        if (error.response && error.response.status === 400) {
            console.log('   - ‚úÖ Error handling working correctly');
            return true;
        } else {
            console.log('   - ‚ö†Ô∏è  Unexpected error:', error.message);
            return true; // Still counts as error handling
        }
    }
}

// Test 6: Performance benchmark
async function testPerformanceBenchmark() {
    console.log('‚úÖ Test 6: Performance Benchmark');
    try {
        const testPrompt = {
            model: MODEL_NAME,
            messages: [
                {
                    role: 'user',
                    content: 'Write a simple JavaScript function to reverse a string'
                }
            ],
            temperature: 0.7,
            max_tokens: 100,
            stream: false
        };
        
        const times = [];
        const numTests = 3;
        
        for (let i = 0; i < numTests; i++) {
            const startTime = Date.now();
            await axios.post(`${OLLAMA_URL}/api/chat`, testPrompt, {
                timeout: 30000,
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            const endTime = Date.now();
            times.push(endTime - startTime);
        }
        
        const avgTime = times.reduce((a, b) => a + b, 0) / times.length;
        const minTime = Math.min(...times);
        const maxTime = Math.max(...times);
        
        console.log('   - üìä Performance results:');
        console.log(`     Average time: ${avgTime.toFixed(0)}ms`);
        console.log(`     Min time: ${minTime}ms`);
        console.log(`     Max time: ${maxTime}ms`);
        
        if (avgTime < 2000) {
            console.log('   - ‚úÖ Performance meets requirements (< 2s average)');
            return true;
        } else {
            console.log('   - ‚ö†Ô∏è  Performance below requirements (> 2s average)');
            return false;
        }
    } catch (error) {
        console.log('   - ‚ùå Performance test failed:', error.message);
        return false;
    }
}

// Main test runner
async function runAllTests() {
    console.log('üöÄ Starting LM Studio Integration Tests...\n');
    
    const tests = [
        testServerConnection,
        testModelAvailability,
        testCodeGeneration,
        testCodeCompletion,
        testErrorHandling,
        testPerformanceBenchmark
    ];
    
    const results = [];
    
    for (const test of tests) {
        try {
            const result = await test();
            results.push(result);
            console.log(''); // Add spacing between tests
        } catch (error) {
            console.log(`   - ‚ùå Test failed with error: ${error.message}`);
            results.push(false);
        }
    }
    
    // Summary
    console.log('üìã Test Summary:');
    const passedTests = results.filter(r => r).length;
    const totalTests = results.length;
    
    console.log(`‚úÖ Passed: ${passedTests}/${totalTests}`);
    console.log(`‚ùå Failed: ${totalTests - passedTests}/${totalTests}`);
    
    if (passedTests === totalTests) {
            console.log('\nüéâ All tests passed! Ollama integration is ready.');
    console.log('\nüìã Next Steps:');
    console.log('1. Test the extension with Cursor IDE');
    console.log('2. Configure extension settings');
    console.log('3. Test real-world code generation scenarios');
    } else {
            console.log('\n‚ö†Ô∏è  Some tests failed. Please check the setup:');
    console.log('1. Ensure Ollama server is running: ollama serve');
    console.log('2. Load Mistral model: ollama pull mistral');
    console.log('3. Check system resources (RAM, CPU)');
    console.log('4. Verify network connectivity');
    }
    
    return passedTests === totalTests;
}

// Run tests if this script is executed directly
if (require.main === module) {
    runAllTests().catch(console.error);
}

module.exports = {
    testServerConnection,
    testModelAvailability,
    testCodeGeneration,
    testCodeCompletion,
    testErrorHandling,
    testPerformanceBenchmark,
    runAllTests
}; 