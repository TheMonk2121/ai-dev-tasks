{"id": "real_001", "query": "How do I run the gold evaluation profile?", "gt_answer": "Use the command: env -u INGEST_RUN_ID -u CHUNK_VARIANT UV_PROJECT_ENVIRONMENT=.venv uv run python scripts/evaluation/ragchecker_official_evaluation.py --profile gold", "tags": ["evaluation", "gold", "command"], "mode": "reader"}
{"id": "real_002", "query": "What is the database connection pattern used in this project?", "gt_answer": "Use Psycopg3Config.get_connection() with resolve_dsn() for DSN resolution", "tags": ["database", "connection", "psycopg3"], "mode": "retrieval"}
{"id": "real_003", "query": "How do I check TimescaleDB telemetry tables?", "gt_answer": "Query eval_run, eval_event, and eval_case_result tables using Psycopg3Config", "tags": ["telemetry", "timescaledb", "monitoring"], "mode": "reader"}
{"id": "real_004", "query": "What environment variables are needed for evaluation runs?", "gt_answer": "POSTGRES_DSN, EVAL_PROFILE, EVAL_DRIVER, RAGCHECKER_USE_REAL_RAG, EVAL_CONCURRENCY", "tags": ["environment", "config", "evaluation"], "mode": "retrieval"}
{"id": "real_005", "query": "Where are evaluation results stored?", "gt_answer": "Results are saved to evals/metrics/dspy_evaluations/ directory as JSON files", "tags": ["results", "storage", "metrics"], "mode": "reader"}
