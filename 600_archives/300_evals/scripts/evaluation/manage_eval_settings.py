#!/usr/bin/env python3
"""
Evaluation Settings Management Script

Provides utilities for managing evaluation system configuration.
"""

import sys
from pathlib import Path

sys.path.append(".")
from src.schemas.settings import settings

def show_current_settings():
    """Display current evaluation settings."""
    print("🔧 Current Evaluation Settings")
    print("=" * 50)

    print("📁 File Paths:")
    print(f"  Gold Cases: {settings.gold_cases_path}")
    print(f"  Manifest: {settings.manifest_path}")
    print(f"  Results Dir: {settings.results_output_dir}")

    print("\n✅ Validation Settings:")
    print(f"  Strict Mode: {settings.validation_strict}")
    print(f"  Allow Missing Files: {settings.allow_missing_files}")
    print(f"  Unknown Tag Warning: {settings.unknown_tag_warning}")
    print(f"  Check File Existence: {settings.check_file_existence}")

    print("\n📊 Evaluation Limits:")
    print(f"  Max Cases Per Eval: {settings.max_cases_per_eval}")
    print(f"  Default Sample Size: {settings.default_sample_size}")

    print("\n⚡ Performance Settings:")
    print(f"  Concurrency Limit: {settings.concurrency_limit}")
    print(f"  Timeout Seconds: {settings.timeout_seconds}")

    print("\n🤖 Model Settings:")
    print(f"  Default Model: {settings.default_model}")
    print(f"  Fallback Model: {settings.fallback_model}")

    print(f"\n🏷️  Known Tags ({len(settings.known_tags)}):")
    for tag in sorted(settings.known_tags):
        print(f"  - {tag}")

def validate_settings():
    """Validate current settings."""
    print("🔍 Validating Settings...")

    issues = []

    # Check file paths
    if not settings.get_gold_cases_path().exists():
        issues.append(f"Gold cases file not found: {settings.gold_cases_path}")

    if not settings.get_manifest_path().exists():
        issues.append(f"Manifest file not found: {settings.manifest_path}")

    # Check numeric ranges
    if not (1 <= settings.max_cases_per_eval <= 1000):
        issues.append(f"max_cases_per_eval must be between 1 and 1000, got {settings.max_cases_per_eval}")

    if not (1 <= settings.concurrency_limit <= 10):
        issues.append(f"concurrency_limit must be between 1 and 10, got {settings.concurrency_limit}")

    if not (30 <= settings.timeout_seconds <= 3600):
        issues.append(f"timeout_seconds must be between 30 and 3600, got {settings.timeout_seconds}")

    if issues:
        print("❌ Settings validation failed:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    else:
        print("✅ All settings are valid")
        return True

def create_env_file():
    """Create a .env file from current settings."""
    env_path = Path(".env")

    if env_path.exists():
        print(f"⚠️  .env file already exists at {env_path}")
        response = input("Overwrite? (y/N): ").strip().lower()
        if response != "y":
            print("Cancelled")
            return

    content = f"""# Evaluation System Configuration
# Generated by manage_eval_settings.py

# File paths
EVAL_GOLD_CASES_PATH={settings.gold_cases_path}
EVAL_MANIFEST_PATH={settings.manifest_path}
EVAL_RESULTS_OUTPUT_DIR={settings.results_output_dir}

# Validation settings
EVAL_VALIDATION_STRICT={str(settings.validation_strict).lower()}
EVAL_ALLOW_MISSING_FILES={str(settings.allow_missing_files).lower()}
EVAL_UNKNOWN_TAG_WARNING={str(settings.unknown_tag_warning).lower()}
EVAL_CHECK_FILE_EXISTENCE={str(settings.check_file_existence).lower()}

# Evaluation limits
EVAL_MAX_CASES_PER_EVAL={settings.max_cases_per_eval}
EVAL_DEFAULT_SAMPLE_SIZE={settings.default_sample_size}

# Performance settings
EVAL_CONCURRENCY_LIMIT={settings.concurrency_limit}
EVAL_TIMEOUT_SECONDS={settings.timeout_seconds}

# Model settings
EVAL_DEFAULT_MODEL={settings.default_model}
EVAL_FALLBACK_MODEL={settings.fallback_model}

# Known tags (comma-separated)
EVAL_KNOWN_TAGS={','.join(settings.known_tags)}
"""

    env_path.write_text(content)
    print(f"✅ Created .env file at {env_path}")

def main():
    """Main CLI interface."""
    if len(sys.argv) < 2:
        print("Usage: python3 scripts/manage_eval_settings.py <command>")
        print("\nCommands:")
        print("  show     - Display current settings")
        print("  validate - Validate current settings")
        print("  create   - Create .env file from current settings")
        return 1

    command = sys.argv[1].lower()

    if command == "show":
        show_current_settings()
    elif command == "validate":
        return 0 if validate_settings() else 1
    elif command == "create":
        create_env_file()
    else:
        print(f"Unknown command: {command}")
        return 1

    return 0

if __name__ == "__main__":
    sys.exit(main())
