{"query": "What is retrieval augmented generation?", "answer": "RAG combines retrieval from knowledge bases with language model generation to provide factual, grounded responses.", "slice_tags": ["single_hop", "structured"], "sub_claims": ["RAG combines retrieval and generation", "uses knowledge bases", "provides grounded responses"], "expected_spans": ["retrieval", "generation", "knowledge bases", "grounded"], "complexity": "single_hop"}
{"query": "How does RAG improve over standard language models and what are its limitations?", "answer": "RAG improves factual accuracy by grounding responses in retrieved documents. However, it can suffer from retrieval failures and increased latency.", "slice_tags": ["multi_hop", "unstructured"], "sub_claims": ["RAG improves factual accuracy", "grounds responses in documents", "can have retrieval failures", "increases latency"], "expected_spans": ["factual accuracy", "retrieved documents", "retrieval failures", "latency"], "complexity": "multi_hop"}
{"query": "Compare BM25 and dense retrieval for RAG systems", "answer": "BM25 uses lexical matching for exact term retrieval, while dense retrieval uses embeddings for semantic similarity. Hybrid approaches combining both often perform best.", "slice_tags": ["multi_hop", "unstructured"], "sub_claims": ["BM25 uses lexical matching", "dense retrieval uses embeddings", "hybrid approaches perform best"], "expected_spans": ["BM25", "lexical", "dense retrieval", "embeddings", "hybrid"], "complexity": "multi_hop"}
{"query": "What is vector similarity search?", "answer": "Vector similarity search finds the most similar embeddings to a query vector using metrics like cosine similarity.", "slice_tags": ["single_hop", "structured"], "sub_claims": ["finds similar embeddings", "uses query vector", "uses cosine similarity"], "expected_spans": ["embeddings", "query vector", "cosine similarity"], "complexity": "single_hop"}
{"query": "How do you evaluate RAG systems across different retrieval methods and what metrics matter most?", "answer": "RAG evaluation uses retrieval metrics (recall, precision) and generation metrics (faithfulness, relevance). The choice depends on whether you prioritize coverage or accuracy.", "slice_tags": ["multi_hop", "unstructured"], "sub_claims": ["uses retrieval metrics", "uses generation metrics", "choice depends on priorities", "coverage vs accuracy tradeoff"], "expected_spans": ["recall", "precision", "faithfulness", "relevance", "coverage", "accuracy"], "complexity": "multi_hop"}
