# Base evaluation configuration
# Common settings for all evaluation runs

# Model configuration
DSPY_MODEL=anthropic.claude-3-haiku-20240307-v1:0
AWS_REGION=us-east-1

# Evaluation settings
EVAL_DISABLE_CACHE=1
DSPY_TELEPROMPT_CACHE=false
TEMPERATURE=0.0

# Concurrency and rate limiting
MAX_WORKERS=3
RATE_LIMIT_PROFILE=stable

# Output paths
METRICS_OUTPUT_DIR=metrics
RESULTS_OUTPUT_DIR=results
