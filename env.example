# Evaluation System Configuration
# Copy this file to .env and customize as needed

# File paths
EVAL_GOLD_CASES_PATH=evals/gold/v1/gold_cases.jsonl
EVAL_MANIFEST_PATH=evals/gold/v1/manifest.json
EVAL_RESULTS_OUTPUT_DIR=metrics/baseline_evaluations

# Validation settings
EVAL_VALIDATION_STRICT=true
EVAL_ALLOW_MISSING_FILES=false
EVAL_UNKNOWN_TAG_WARNING=true
EVAL_CHECK_FILE_EXISTENCE=true

# Evaluation limits
EVAL_MAX_CASES_PER_EVAL=100
EVAL_DEFAULT_SAMPLE_SIZE=50

# Performance settings
EVAL_CONCURRENCY_LIMIT=3
EVAL_TIMEOUT_SECONDS=300

# Model settings
EVAL_DEFAULT_MODEL=anthropic.claude-3-haiku-20240307-v1:0
EVAL_FALLBACK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Known tags (comma-separated)
EVAL_KNOWN_TAGS=ops_health,meta_ops,rag_qa_single,rag_qa_multi,db_workflows,negatives,rag,dspy,memory,context
