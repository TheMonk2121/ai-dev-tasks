#!/usr/bin/env python3
"""
Phase 5: Advanced Orchestration Features
Enhanced MCP Server Orchestration with retry logic, caching, and advanced monitoring
"""

import asyncio
import hashlib
import json
import logging
import statistics
import time
from collections import deque
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, Optional, Tuple

import aiohttp

logger = logging.getLogger(__name__)


class CircuitBreakerState(Enum):
    """Circuit breaker states"""

    CLOSED = "closed"  # Normal operation
    OPEN = "open"  # Failing, reject requests
    HALF_OPEN = "half_open"  # Testing if service recovered


@dataclass
class RetryConfig:
    """Configuration for retry logic"""

    max_retries: int = 3
    base_delay: float = 1.0
    max_delay: float = 30.0
    exponential_backoff: bool = True
    jitter: bool = True


@dataclass
class CacheConfig:
    """Configuration for caching"""

    max_size: int = 1000
    ttl_seconds: int = 300
    enable_compression: bool = True
    cache_by_user: bool = True


@dataclass
class AdvancedMetrics:
    """Advanced metrics for orchestration monitoring"""

    # Performance metrics
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    retry_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0

    # Timing metrics
    avg_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0
    response_times: deque = field(default_factory=lambda: deque(maxlen=1000))

    # Circuit breaker metrics
    circuit_breaker_trips: int = 0
    circuit_breaker_resets: int = 0

    # Server-specific metrics
    server_metrics: Dict[str, Dict[str, Any]] = field(default_factory=dict)

    def update_response_time(self, response_time: float):
        """Update response time metrics"""
        self.response_times.append(response_time)

        if self.response_times:
            times = list(self.response_times)
            self.avg_response_time = statistics.mean(times)
            if len(times) >= 5:
                self.p95_response_time = statistics.quantiles(times, n=20)[18]  # 95th percentile
            if len(times) >= 10:
                self.p99_response_time = statistics.quantiles(times, n=100)[98]  # 99th percentile


class CircuitBreaker:
    """Enhanced circuit breaker with advanced state management"""

    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.last_failure_time = 0
        self.success_count = 0
        self.half_open_threshold = 3

    def can_execute(self) -> bool:
        """Check if request can be executed"""
        if self.state == CircuitBreakerState.OPEN:
            if time.time() - self.last_failure_time >= self.recovery_timeout:
                self.state = CircuitBreakerState.HALF_OPEN
                logger.info("Circuit breaker transitioning to HALF_OPEN")
                return True
            return False
        return True

    def on_success(self):
        """Handle successful request"""
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.half_open_threshold:
                self.state = CircuitBreakerState.CLOSED
                self.failure_count = 0
                self.success_count = 0
                logger.info("Circuit breaker reset to CLOSED")
        else:
            self.failure_count = 0

    def on_failure(self):
        """Handle failed request"""
        self.failure_count += 1
        self.last_failure_time = time.time()

        if self.state == CircuitBreakerState.CLOSED and self.failure_count >= self.failure_threshold:
            self.state = CircuitBreakerState.OPEN
            logger.warning(f"Circuit breaker opened after {self.failure_count} failures")
        elif self.state == CircuitBreakerState.HALF_OPEN:
            self.state = CircuitBreakerState.OPEN
            self.success_count = 0
            logger.warning("Circuit breaker reopened after failure in HALF_OPEN state")


class ResponseCache:
    """Advanced response caching with compression and user isolation"""

    def __init__(self, config: CacheConfig):
        self.config = config
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.access_times: Dict[str, float] = {}
        self.user_caches: Dict[str, Dict[str, Any]] = {}

    def _generate_cache_key(self, tool_name: str, arguments: Dict[str, Any], user_id: Optional[str] = None) -> str:
        """Generate cache key for request"""
        # Create deterministic key
        key_data = {"tool": tool_name, "args": sorted(arguments.items()), "user": user_id or "anonymous"}
        key_string = json.dumps(key_data, sort_keys=True)
        return hashlib.sha256(key_string.encode()).hexdigest()

    def get(self, tool_name: str, arguments: Dict[str, Any], user_id: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """Get cached response"""
        cache_key = self._generate_cache_key(tool_name, arguments, user_id)

        # Check main cache
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            if time.time() - entry["timestamp"] < self.config.ttl_seconds:
                self.access_times[cache_key] = time.time()
                return entry["data"]
            else:
                # Expired, remove
                del self.cache[cache_key]
                if cache_key in self.access_times:
                    del self.access_times[cache_key]

        # Check user-specific cache
        if self.config.cache_by_user and user_id:
            user_cache = self.user_caches.get(user_id, {})
            if cache_key in user_cache:
                entry = user_cache[cache_key]
                if time.time() - entry["timestamp"] < self.config.ttl_seconds:
                    return entry["data"]

        return None

    def set(self, tool_name: str, arguments: Dict[str, Any], response: Dict[str, Any], user_id: Optional[str] = None):
        """Cache response"""
        cache_key = self._generate_cache_key(tool_name, arguments, user_id)
        timestamp = time.time()

        entry = {"data": response, "timestamp": timestamp, "tool": tool_name, "user": user_id}

        # Add to main cache
        if len(self.cache) >= self.config.max_size:
            self._evict_oldest()

        self.cache[cache_key] = entry
        self.access_times[cache_key] = timestamp

        # Add to user cache if enabled
        if self.config.cache_by_user and user_id:
            if user_id not in self.user_caches:
                self.user_caches[user_id] = {}
            self.user_caches[user_id][cache_key] = entry

    def _evict_oldest(self):
        """Evict oldest cache entries"""
        if not self.access_times:
            return

        oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        del self.cache[oldest_key]
        del self.access_times[oldest_key]


class RetryManager:
    """Advanced retry logic with exponential backoff and jitter"""

    def __init__(self, config: RetryConfig):
        self.config = config

    async def execute_with_retry(self, func, *args, **kwargs) -> Tuple[Any, int]:
        """Execute function with retry logic"""
        last_exception = None
        retry_count = 0

        for attempt in range(self.config.max_retries + 1):
            try:
                start_time = time.time()
                result = await func(*args, **kwargs)
                response_time = (time.time() - start_time) * 1000

                logger.info(f"Request succeeded on attempt {attempt + 1} (response_time: {response_time:.1f}ms)")
                return result, retry_count

            except Exception as e:
                last_exception = e
                retry_count = attempt

                if attempt < self.config.max_retries:
                    delay = self._calculate_delay(attempt)
                    logger.warning(f"Request failed on attempt {attempt + 1}: {e}. Retrying in {delay:.1f}s")
                    await asyncio.sleep(delay)
                else:
                    logger.error(f"Request failed after {self.config.max_retries + 1} attempts: {e}")

        if last_exception is not None:
            raise last_exception
        else:
            raise Exception("Request failed but no exception was captured")

    def _calculate_delay(self, attempt: int) -> float:
        """Calculate delay for retry attempt"""
        if self.config.exponential_backoff:
            delay = self.config.base_delay * (2**attempt)
        else:
            delay = self.config.base_delay

        delay = min(delay, self.config.max_delay)

        if self.config.jitter:
            # Add random jitter (Â±25%)
            import random

            jitter = random.uniform(0.75, 1.25)
            delay *= jitter

        return delay


class AdvancedOrchestrator:
    """Enhanced orchestrator with advanced features"""

    def __init__(self, retry_config: Optional[RetryConfig] = None, cache_config: Optional[CacheConfig] = None):
        self.retry_config = retry_config or RetryConfig()
        self.cache_config = cache_config or CacheConfig()

        self.retry_manager = RetryManager(self.retry_config)
        self.response_cache = ResponseCache(self.cache_config)
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.metrics = AdvancedMetrics()

        # Server registry
        self.servers: Dict[str, Dict[str, Any]] = {}

    def register_server(self, server_id: str, server_info: Dict[str, Any]):
        """Register a server with the orchestrator"""
        self.servers[server_id] = server_info
        self.circuit_breakers[server_id] = CircuitBreaker()
        self.metrics.server_metrics[server_id] = {
            "requests": 0,
            "successes": 0,
            "failures": 0,
            "avg_response_time": 0.0,
            "last_request": 0,
        }
        logger.info(f"Registered server: {server_id}")

    async def execute_tool(
        self, tool_name: str, arguments: Dict[str, Any], user_id: Optional[str] = None, server_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """Execute tool with advanced orchestration features"""

        self.metrics.total_requests += 1

        # Check cache first
        cached_response = self.response_cache.get(tool_name, arguments, user_id)
        if cached_response:
            self.metrics.cache_hits += 1
            logger.info(f"Cache hit for tool: {tool_name}")
            return cached_response

        self.metrics.cache_misses += 1

        # Select server
        if server_id and server_id in self.servers:
            selected_server = server_id
        else:
            selected_server = self._select_server(tool_name)

        if not selected_server:
            raise Exception("No available servers for tool execution")

        # Check circuit breaker
        circuit_breaker = self.circuit_breakers[selected_server]
        if not circuit_breaker.can_execute():
            raise Exception(f"Circuit breaker open for server: {selected_server}")

        # Execute with retry logic
        try:
            start_time = time.time()
            result, retry_count = await self.retry_manager.execute_with_retry(
                self._execute_on_server, selected_server, tool_name, arguments
            )
            response_time = (time.time() - start_time) * 1000

            # Update metrics
            self.metrics.successful_requests += 1
            self.metrics.retry_count += retry_count
            self.metrics.update_response_time(response_time)
            self._update_server_metrics(selected_server, True, response_time)

            # Update circuit breaker
            circuit_breaker.on_success()

            # Cache successful response
            self.response_cache.set(tool_name, arguments, result, user_id)

            logger.info(
                f"Tool execution successful: {tool_name} on {selected_server} "
                f"(response_time: {response_time:.1f}ms, retries: {retry_count})"
            )

            return result

        except Exception as e:
            # Update metrics
            self.metrics.failed_requests += 1
            self._update_server_metrics(selected_server, False, 0)

            # Update circuit breaker
            circuit_breaker.on_failure()

            logger.error(f"Tool execution failed: {tool_name} on {selected_server}: {e}")
            raise

    def _select_server(self, tool_name: str) -> Optional[str]:
        """Select server for tool execution"""
        available_servers = [
            server_id
            for server_id, server_info in self.servers.items()
            if self.circuit_breakers[server_id].state != CircuitBreakerState.OPEN
        ]

        if not available_servers:
            return None

        # Simple round-robin for now
        # Could be enhanced with load balancing, health checks, etc.
        return available_servers[0]

    async def _execute_on_server(self, server_id: str, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Execute tool on specific server using proper MCP protocol"""
        server_info = self.servers[server_id]
        url = f"{server_info['url']}/mcp/tools/call"

        # Use the format expected by our MCP server
        payload = {"name": tool_name, "arguments": arguments}

        async with aiohttp.ClientSession() as session:
            timeout = aiohttp.ClientTimeout(total=30)
            async with session.post(url, json=payload, timeout=timeout) as response:
                if response.status == 200:
                    result = await response.json()
                    return result
                else:
                    raise Exception(f"Server returned status {response.status}")

    def _update_server_metrics(self, server_id: str, success: bool, response_time: float):
        """Update server-specific metrics"""
        if server_id in self.metrics.server_metrics:
            metrics = self.metrics.server_metrics[server_id]
            metrics["requests"] += 1
            metrics["last_request"] = time.time()

            if success:
                metrics["successes"] += 1
                if metrics["avg_response_time"] == 0:
                    metrics["avg_response_time"] = response_time
                else:
                    metrics["avg_response_time"] = (metrics["avg_response_time"] * 0.9) + (response_time * 0.1)
            else:
                metrics["failures"] += 1

    def get_metrics(self) -> Dict[str, Any]:
        """Get comprehensive metrics"""
        return {
            "performance": {
                "total_requests": self.metrics.total_requests,
                "successful_requests": self.metrics.successful_requests,
                "failed_requests": self.metrics.failed_requests,
                "success_rate": (
                    (self.metrics.successful_requests / self.metrics.total_requests * 100)
                    if self.metrics.total_requests > 0
                    else 0
                ),
                "avg_response_time": self.metrics.avg_response_time,
                "p95_response_time": self.metrics.p95_response_time,
                "p99_response_time": self.metrics.p99_response_time,
                "retry_count": self.metrics.retry_count,
                "avg_retries_per_request": (
                    (self.metrics.retry_count / self.metrics.total_requests) if self.metrics.total_requests > 0 else 0
                ),
            },
            "caching": {
                "cache_hits": self.metrics.cache_hits,
                "cache_misses": self.metrics.cache_misses,
                "cache_hit_rate": (
                    (self.metrics.cache_hits / (self.metrics.cache_hits + self.metrics.cache_misses) * 100)
                    if (self.metrics.cache_hits + self.metrics.cache_misses) > 0
                    else 0
                ),
            },
            "circuit_breakers": {
                server_id: {
                    "state": cb.state.value,
                    "failure_count": cb.failure_count,
                    "success_count": cb.success_count,
                }
                for server_id, cb in self.circuit_breakers.items()
            },
            "servers": self.metrics.server_metrics,
        }


class IntegrationTestSuite:
    """Integration testing suite for orchestration features"""

    def __init__(self, orchestrator: AdvancedOrchestrator):
        self.orchestrator = orchestrator
        self.test_results = []

    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all integration tests"""
        logger.info("ð§ª Starting integration test suite...")

        tests = [
            ("Basic Tool Execution", self.test_basic_tool_execution),
            ("Retry Logic", self.test_retry_logic),
            ("Caching", self.test_caching),
            ("Circuit Breaker", self.test_circuit_breaker),
            ("Load Balancing", self.test_load_balancing),
            ("Error Handling", self.test_error_handling),
            ("Performance", self.test_performance),
        ]

        results = {}
        for test_name, test_func in tests:
            try:
                logger.info(f"Running test: {test_name}")
                start_time = time.time()
                result = await test_func()
                duration = time.time() - start_time

                results[test_name] = {"status": "PASSED", "duration": duration, "details": result}
                logger.info(f"â {test_name}: PASSED ({duration:.2f}s)")

            except Exception as e:
                results[test_name] = {"status": "FAILED", "duration": 0, "error": str(e)}
                logger.error(f"â {test_name}: FAILED - {e}")

        return results

    async def test_basic_tool_execution(self) -> Dict[str, Any]:
        """Test basic tool execution"""
        result = await self.orchestrator.execute_tool(
            "rehydrate_memory", {"role": "coder", "task": "test", "limit": 100}, user_id="test_user"
        )

        return {
            "tool_executed": "rehydrate_memory",
            "result_keys": list(result.keys()) if isinstance(result, dict) else [],
            "success": True,
        }

    async def test_retry_logic(self) -> Dict[str, Any]:
        """Test retry logic with simulated failures"""
        # This would test retry behavior with a mock server that fails occasionally
        return {"retry_config": self.orchestrator.retry_config.__dict__}

    async def test_caching(self) -> Dict[str, Any]:
        """Test caching functionality"""
        # Execute same tool twice
        args = {"role": "coder", "task": "cache_test", "limit": 50}

        # First call (cache miss)
        await self.orchestrator.execute_tool("rehydrate_memory", args, user_id="test_user")
        cache_misses_before = self.orchestrator.metrics.cache_misses

        # Second call (cache hit)
        await self.orchestrator.execute_tool("rehydrate_memory", args, user_id="test_user")
        cache_hits_after = self.orchestrator.metrics.cache_hits

        return {
            "cache_misses": cache_misses_before,
            "cache_hits": cache_hits_after,
            "caching_working": cache_hits_after > 0,
        }

    async def test_circuit_breaker(self) -> Dict[str, Any]:
        """Test circuit breaker functionality"""
        circuit_breaker_states = {
            server_id: cb.state.value for server_id, cb in self.orchestrator.circuit_breakers.items()
        }

        return {
            "circuit_breaker_states": circuit_breaker_states,
            "all_servers_available": all(
                cb.state != CircuitBreakerState.OPEN for cb in self.orchestrator.circuit_breakers.values()
            ),
        }

    async def test_load_balancing(self) -> Dict[str, Any]:
        """Test load balancing across servers"""
        server_requests = {
            server_id: metrics["requests"] for server_id, metrics in self.orchestrator.metrics.server_metrics.items()
        }

        return {
            "server_requests": server_requests,
            "load_distribution": "balanced" if len(set(server_requests.values())) <= 1 else "unbalanced",
        }

    async def test_error_handling(self) -> Dict[str, Any]:
        """Test error handling"""
        try:
            # Try to execute non-existent tool
            await self.orchestrator.execute_tool("non_existent_tool", {})
            return {"error_handling": "FAILED - Should have raised exception"}
        except Exception as e:
            return {"error_handling": "PASSED", "exception_type": type(e).__name__}

    async def test_performance(self) -> Dict[str, Any]:
        """Test performance metrics"""
        metrics = self.orchestrator.get_metrics()

        return {
            "avg_response_time": metrics["performance"]["avg_response_time"],
            "success_rate": metrics["performance"]["success_rate"],
            "cache_hit_rate": metrics["caching"]["cache_hit_rate"],
            "performance_acceptable": metrics["performance"]["avg_response_time"] < 1000,  # < 1 second
        }


async def main():
    """Main function to demonstrate Phase 5 features"""

    print("ð Phase 5: Advanced Orchestration Features")
    print("=" * 60)

    # Create advanced orchestrator
    retry_config = RetryConfig(max_retries=3, base_delay=1.0, exponential_backoff=True)
    cache_config = CacheConfig(max_size=500, ttl_seconds=300, cache_by_user=True)

    orchestrator = AdvancedOrchestrator(retry_config, cache_config)

    # Register servers
    orchestrator.register_server(
        "server_1",
        {
            "url": "http://localhost:3000",
            "name": "MCP Memory Server 1",
            "capabilities": ["memory", "context", "github", "database"],
        },
    )

    orchestrator.register_server(
        "server_2",
        {
            "url": "http://localhost:3001",
            "name": "MCP Memory Server 2",
            "capabilities": ["memory", "context", "github", "database"],
        },
    )

    print("â Servers registered")

    # Run integration tests
    test_suite = IntegrationTestSuite(orchestrator)
    test_results = await test_suite.run_all_tests()

    print("\nð Test Results:")
    for test_name, result in test_results.items():
        status = result["status"]
        duration = result.get("duration", 0)
        print(f"  {test_name}: {status} ({duration:.2f}s)")

    # Show metrics
    metrics = orchestrator.get_metrics()
    print("\nð Performance Metrics:")
    print(f"  Total Requests: {metrics['performance']['total_requests']}")
    print(f"  Success Rate: {metrics['performance']['success_rate']:.1f}%")
    print(f"  Avg Response Time: {metrics['performance']['avg_response_time']:.1f}ms")
    print(f"  Cache Hit Rate: {metrics['caching']['cache_hit_rate']:.1f}%")

    print("\nð Phase 5 Advanced Features Complete!")


if __name__ == "__main__":
    asyncio.run(main())
