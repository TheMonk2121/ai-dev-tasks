# ğŸ—ï¸ System Overview & Architecture

<!-- ANCHOR_KEY: system-overview-architecture -->
<!-- ANCHOR_PRIORITY: 4 -->
<!-- ROLE_PINS: ["researcher", "implementer"] -->

## ğŸ” TL;DR

| what this file is | read when | do next |
|---|---|---|
| Canonical system and architecture overview for understanding the codebase | Need to understand the technical architecture, system components, or how everything fits together | Read 04 (Development Workflows) then 05 (Coding Standards) |

- **what this file is**: Complete technical map of the system architecture and core components.

- **read when**: When you need to understand the technical architecture, system components, or how everything fits together.

- **do next**: Read 04 (Development Workflows & Standards) then 05 (Codebase Organization & Patterns).

## ğŸ¯ **Current Status**
- **Priority**: ğŸ”¥ **HIGH** - Essential for understanding codebase architecture
- **Phase**: 2 of 4 (Codebase Development)
- **Dependencies**: 00-02 (Memory System Foundation)

## ğŸ¯ **Purpose**

Provide a complete architecture map, core components, interfaces, and flows across planning, development, automation, deployment, observability, and security. This file is the canonical architectural source; details live in linked guides to avoid duplication.

## ğŸ§± Architecture Layers

- Presentation & Tooling
  - Cursor Native AI, mission dashboard, CLI/tooling
- Application Services
  - DSPy modules, automation services, background workers (RAG, rehydrator, pipelines)
- Data Layer
  - PostgreSQL + PGVector; optional Redis; logs/metrics storage
- Observability & Security
  - Health checks, metrics, tracing, access control, validation

## ğŸ”„ Core Flows

- Development Flow: Backlog â†’ Plan â†’ Implement â†’ Test â†’ Deploy â†’ Observe
- Context Flow: Memory rehydration â†’ roleâ€‘aware bundles â†’ echo verification â†’ selfâ€‘critique
- Automation Flow: n8n workflows, Scribe capture â†’ notifications â†’ dashboards

## ğŸ—ºï¸ Map of Topics (Anchors)

- Architecture: highâ€‘level system map
- Context Management: memory, vector, entity expansion, RRF
- Core Components: planner/AI execution layer and services
- Workflow: endâ€‘toâ€‘end development flow
- Security: guardrails and controls
- Testing & Quality: strategy and quality gates
- Deployment & Ops: environments, runtime, observability

## ğŸ“š **Documentation Reference & Navigation**

### **ğŸš¨ CRITICAL: Documentation Reference is Essential**

**Why This Matters**: The documentation reference system provides the complete map of all documentation, their relationships, and navigation patterns. Without proper reference integration, users cannot efficiently navigate the documentation system or understand how different guides relate to each other.

### **Complete Documentation Inventory**

#### **Core Documentation Structure**
```bash
# Essential Files (Tier 1 - Critical)
100_memory/100_cursor-memory-context.md          # Memory scaffold and current state
000_core/000_backlog.md                          # Priorities and dependencies
400_guides/400_03_system-overview-and-architecture.md  # This guide
400_guides/400_00_getting-started-and-index.md   # Entry point and navigation
400_guides/400_04_development-workflow-and-standards.md  # Development workflows
400_guides/400_02_governance-and-ai-constitution.md     # AI safety and governance
400_guides/400_01_documentation-playbook.md      # File management rules
400_guides/400_11_deployments-ops-and-observability.md  # Deployment and operations
400_guides/400_cursor-context-engineering-guide.md      # Cursor integration

# Workflow Files
000_core/001_create-prd.md                       # PRD creation workflow
000_core/002_generate-tasks.md                   # Task generation workflow
000_core/003_process-task-list.md                # AI execution workflow

# Setup and Configuration
200_setup/202_setup-requirements.md              # Environment setup
100_memory/104_dspy-development-context.md       # DSPy architecture details
```

#### **Documentation Tier System**
- **Tier 1 (Critical - Priority 0-10)**: Core memory context, system overview, backlog
- **Tier 2 (High - Priority 15-20)**: Important guides, code quality, security
- **Tier 3 (Medium - Priority 25-30)**: Implementation guides, deployment, testing
- **Tier 4 (Lower - Priority 35-40)**: PRDs, research, examples

### **Context-Specific Reading Guidance**

#### **For New Sessions**
1. **`400_guides/400_00_getting-started-and-index.md`** â†’ Entry point and project overview
2. **`100_memory/100_cursor-memory-context.md`** â†’ Current state and rules
3. **`000_core/000_backlog.md`** â†’ Priorities and dependencies
4. **`400_guides/400_03_system-overview-and-architecture.md`** â†’ This guide for architecture

#### **For Development Work**
1. **`400_guides/400_04_development-workflow-and-standards.md`** â†’ Complete development workflow
2. **`400_guides/400_05_codebase-organization-patterns.md`** â†’ Code organization and patterns
3. **`400_guides/400_09_ai-frameworks-dspy.md`** â†’ AI framework integration
4. **`400_guides/400_11_performance-optimization.md`** â†’ Performance optimization

#### **For Research & Analysis**
1. **`500_research/500_research-index.md`** â†’ Research overview and methodology
2. **`500_research/500_dspy-research.md`** â†’ DSPy-specific research
3. **`500_research/500_rag-system-research.md`** â†’ RAG system research

#### **For File Management**
1. **`400_guides/400_01_documentation-playbook.md`** â†’ MANDATORY file analysis rules
2. **`200_setup/200_naming-conventions.md`** â†’ File placement and naming
3. **`400_guides/400_06_memory-and-context-systems.md`** â†’ Documentation categorization

### **Cross-Reference System**

#### **Cross-Reference Quality Metrics**
- **High Coverage**: 400_context-priority-guide.md (72% cross-references)
- **Medium Coverage**: 400_ai-constitution.md, 400_development-workflow.md (38-48%)
- **Low Coverage**: 400_deployment-operations.md, 400_performance-optimization-guide.md (3-4%)
- **Average Coverage**: 35% across all 400_guides files

#### **Navigation Patterns**
- **Safety-First**: AI constitution and file analysis guides prominently referenced
- **Quality-Focused**: Code criticality and testing strategy guides well-linked
- **Development-Oriented**: Project overview and system overview central to navigation
- **Specialized Access**: Deployment, integration, migration guides available for specific tasks

### **Documentation Health Monitoring**

#### **Health Check Commands**
```bash
# Check documentation health
python3 scripts/documentation_health_check.py

# Validate cross-references
python3 scripts/validate_cross_references.py

# Check for broken links
python3 scripts/check_broken_links.py

# Documentation coherence validation
python3 scripts/doc_coherence_validator.py
```

#### **Documentation Quality Gates**
- **Cross-Reference Coverage**: Minimum 30% cross-reference coverage
- **Link Validation**: All internal links must be valid
- **Content Freshness**: Core guides updated within last 30 days
- **Structure Consistency**: All guides follow standard structure

## ğŸ›¡ï¸ Safety Ops Anchors (Constitution)

**Critical Policies**: See `100_memory/100_cursor-memory-context.md#critical-policies` for essential safety guidelines.

- **File Safety**: Pre-edit analysis and protected file tiers
- **Context Rehydration**: Entrypoints via `scripts/memory_up.sh`, memory scaffold, backlog
- **Enforcement Hooks**: Testing gates, DSPy assertions, CI validators
- **Cross-Reference Integrity**: Architecture owns canonical links between 00-12 guides

## Architecture (highâ€‘level)

Refer to `400_system-overview.md` for the full detailed architecture and component deep dives. Key excerpted structure:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core Systems                                                â”‚
â”‚  â”œâ”€ DSPy Multiâ€‘Agent & RAG systems                           â”‚
â”‚  â”œâ”€ Scribe (Context Capture & Summarization)                 â”‚
â”‚  â”œâ”€ n8n Workflows (Automation)                               â”‚
â”‚  â””â”€ Dashboard (Monitoring)                                   â”‚
â”‚                                                              â”‚
â”‚  Supporting Infrastructure                                   â”‚
â”‚  â”œâ”€ PostgreSQL + PGVector                                    â”‚
â”‚  â”œâ”€ Optional Redis cache                                     â”‚
â”‚  â””â”€ Structured tracing & logs                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See: `400_system-overview.md` (Architecture, Core Components, Testing Framework, Metadata System).

## Context Management (summary)

- **Unified Memory Orchestrator**: Single command access to all memory systems
  - Automatic database startup via `brew services start postgresql@14`
  - Automatic virtual environment activation and dependency setup
  - Health monitoring with progress indicators and timeout handling
  - Graceful degradation when database startup is slow
- **Memory System Components**:
  - **LTST Memory System**: Database-backed conversation memory with session tracking
  - **Cursor Memory**: Static documentation bundling via `memory_up.sh`
  - **Go CLI Memory**: Fast startup (<1s) with lean hybrid approach
  - **Prime Cursor**: Enhanced Cursor integration with chat capabilities
- **Context Store**: Postgres tables; vector store via PGVector
- **Context Cache**: inâ€‘memory/Redis; TTL and invalidation policies
- **Entity Expansion**: patternâ€‘based extraction; adjacent retrieval
- **RRF Fusion**: combine vector + BM25; stability slider and killâ€‘switches

## Retrieval System Architecture (B-1059)

The retrieval system implements a comprehensive tuning protocol with production-grade reliability:

### Core Components

- **Fusion Engine** (`src/retrieval/fusion.py`): Weighted RRF combining BM25 and vector search
- **Pre-filter System** (`src/retrieval/prefilter.py`): Recall-friendly filtering with diversity preservation
- **Reranking Engine** (`src/retrieval/reranker.py`): Heuristic-based reranking with configurable weights
- **Context Packer** (`src/retrieval/packer.py`): MMR-based context selection with token limits
- **Intent Router** (`src/retrieval/intent_router.py`): Query-aware parameter adjustment
- **Quality Gates** (`src/retrieval/quality_gates.py`): Configurable evaluation thresholds

### System Flow

```
Query Input â†’ Intent Detection â†’ Fusion â†’ Pre-filter â†’ Rerank â†’ Pack â†’ Generate
     â†“              â†“           â†“         â†“         â†“       â†“       â†“
Intent Router â†’ Fusion Config â†’ Filter â†’ Reranker â†’ Packer â†’ LLM
     â†“              â†“           â†“         â†“         â†“       â†“
Policy Config â†’ Weights â†’ Thresholds â†’ Alpha â†’ MMR â†’ Response
```

### Configuration Management

- **Single Source of Truth**: `config/retrieval.yaml` for all parameters
- **Intent-Based Routing**: Dynamic parameter adjustment based on query type
- **Quality Gates**: Soft (warnings) and hard (failures) evaluation thresholds
- **Performance Targets**: Recall@20: 0.35, F1: 0.22, Faithfulness: 0.60

### Testing & Validation

- **Comprehensive Test Suite**: Edge cases, robustness, failure modes
- **Health Monitoring**: Real-time component status and performance metrics
- **CI/CD Integration**: Quality gates in GitHub Actions with soft enforcement
- **Performance Tuning**: Hyperparameter optimization via `scripts/tune_retrieval.py`

### Operational Features

- **Edge Case Handling**: Empty queries, unicode, special characters, very long queries
- **Robustness Checks**: High volume, memory pressure, concurrent queries
- **Health Monitoring**: Latency tracking, success rate, error rate, component health
- **Failure Recovery**: Graceful degradation and fallback strategies

See: `config/retrieval.yaml` for configuration, `scripts/test_retrieval_system.py` for testing, and individual component files in `src/retrieval/` for implementation details.

**Command**: `python3 scripts/unified_memory_orchestrator.py --systems ltst cursor go_cli prime --role planner "query"`

See: `400_06_memory-and-context-systems.md` and `dspy-rag-system/src/utils/memory_rehydrator.py`.

## AI Execution Layer (summary)

- Router: IntentRouter â†’ RetrievalAgent â†’ CodeAgent (fastâ€‘path bypass for trivial asks)
- Timeouts and backoff; model janitor; scoreâ€‘aware prioritization
- State file: `.ai_state.json` for continuity
- **RAGChecker Evaluation**: Industry-standard RAG evaluation framework for quality assessment
- **RAGChecker + Pydantic Integration**: Enhanced data validation, type safety, and performance optimization

See: `400_07_ai-frameworks-dspy.md` and `400_05_coding-and-prompting-standards.md`.

## Observability & Runtime

- Structured tracing, cryptographic verification, echo verification, selfâ€‘critique
- Health endpoints; metrics; dashboards; alerts
- **RAGChecker Metrics**: Precision, Recall, F1 Score, Context Utilization for RAG system quality
- **Performance Monitoring**: Real-time performance tracking, alerting, and optimization for validation workflows

See: `400_11_deployments-ops-and-observability.md` and `400_observability-system.md`.

## Security & Compliance (summary)

- Input validation; access control; secrets management
- Defenseâ€‘inâ€‘depth; environment isolation; monitoring

See: `400_10_security-compliance-and-access.md`.

## Development Workflow (pointer)

For how to build and ship changes endâ€‘toâ€‘end, see `400_04_development-workflow-and-standards.md`.

## ğŸ“¦ Canonical References

- Memory System Overview: `400_guides/400_00_memory-system-overview.md`
- Memory System Architecture: `400_guides/400_01_memory-system-architecture.md`
- Memory Rehydration: `400_guides/400_02_memory-rehydration-context-management.md`
- Development Workflow: `400_guides/400_04_development-workflow-and-standards.md`
- Codebase Organization: `400_guides/400_05_codebase-organization-patterns.md`
- AI Frameworks (DSPy/MCP): `400_guides/400_07_ai-frameworks-dspy.md`
- RAGChecker Evaluation: `400_guides/400_07_ai-frameworks-dspy.md#ragchecker-evaluation-system`
- MCP Memory Server: `400_guides/400_01_memory-system-architecture.md#mcp-memory-server-integration`
- Integrations: `400_guides/400_08_integrations-editor-and-models.md`
- Automation & Pipelines: `400_guides/400_09_automation-and-pipelines.md`
- Security & Access: `400_guides/400_10_security-compliance-and-access.md`
- Deployments/Ops: `400_guides/400_11_deployments-ops-and-observability.md`
- Product & Roadmap: `400_guides/400_12_product-management-and-roadmap.md`

## ğŸ§© Design Principles

- One canonical home per topic; link instead of duplicate
- Evidenceâ€‘first documentation; all links resolve
- Progressive hardening: preâ€‘commit/CI gates, link validation, security checks

## ğŸ”— Interfaces

- Backlog: `000_core/000_backlog.md`
- Memory Context: `100_memory/100_cursor-memory-context.md`
- DSPy Modules: See `400_07_ai-frameworks-dspy.md`

## ğŸ“š References

- System Overview (detailed): `400_system-overview.md`
- Documentation Playbook: `400_01_documentation-playbook.md`
- Security Best Practices: `400_10_security-compliance-and-access.md`
- Deployments & Ops: `400_11_deployments-ops-and-observability.md`

### **ğŸ§ª Testing & Methodology Documentation**

**Comprehensive Testing Coverage**: `300_experiments/300_complete-testing-coverage.md`
- **Purpose**: Complete overview of all testing and methodology coverage
- **Coverage**: Navigation guide, usage instructions, best practices

## ğŸ”§ **System Integration & Deployment**

### **ğŸš¨ CRITICAL: System Integration & Deployment are Essential**

**Why This Matters**: System integration and deployment provide the mechanisms for connecting components, managing environments, and ensuring reliable system operation. Without proper integration, components remain isolated, system functionality is limited, and operational efficiency is compromised.

### **Integration Framework & Patterns**

#### **Component Integration Strategies**
- **API Integration**: RESTful and GraphQL service integration
- **Database Integration**: Relational and NoSQL database connectivity
- **Message Queue Integration**: Asynchronous communication and event handling
- **Service Mesh Integration**: Microservices communication and discovery

#### **Deployment Strategies**
- **Container Deployment**: Docker and Kubernetes orchestration
- **Cloud Deployment**: Multi-cloud and hybrid cloud strategies
- **CI/CD Integration**: Automated build, test, and deployment pipelines
- **Environment Management**: Development, staging, and production environments

## ğŸ­ **Cursor Role System Alignment**

### **ğŸš¨ CRITICAL: Role System Alignment is Essential**

**Why This Matters**: Cursor's role system operates as a high-level memory layer that must be seamlessly integrated with our existing memory infrastructure. Without proper alignment, AI agents cannot provide consistent, role-specific guidance or leverage the full power of the memory system.

### **Role System Architecture**

#### **Multi-File Role System (New)**
```bash
# Cursor's new multi-file role system
.cursorrules                           # Main role configuration
.vscode/settings.json                  # VS Code role settings
role-specific configuration files      # Individual role configurations
```

#### **Single-File Role System (Legacy)**
```bash
# Cursor's legacy single-file role system
.cursorrules                           # All role configurations in one file
```

### **Role System Components**

#### **Core Role Types**
1. **Planner Role** - Strategic analysis, planning, and high-level decision making
2. **Implementer Role** - Technical implementation and workflow design
3. **Researcher Role** - Research methodology and evidence-based analysis
4. **Coder Role** - Code implementation and technical patterns

#### **Role System Features**
- **Context-Aware Responses**: Role-specific context and insights
- **Memory Integration**: Seamless access to memory system
- **Workflow Alignment**: Role-specific workflows and processes
- **Performance Optimization**: Role-specific performance tuning

### **Alignment Patterns**

#### **1. Memory System Integration**

##### **Unified Memory Orchestrator Integration**
```bash
# Role-specific memory access
python3 scripts/unified_memory_orchestrator.py --systems cursor --role planner "query"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role implementer "query"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role researcher "query"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role coder "query"
```

##### **Memory Context Alignment**
```bash
# Role-specific memory context
export POSTGRES_DSN="mock://test"
python3 scripts/unified_memory_orchestrator.py --systems ltst cursor go_cli prime --role planner "current project status"
```

#### **2. Role-Specific Context Patterns**

##### **Planner Role Context**
```bash
# Strategic planning context
python3 scripts/unified_memory_orchestrator.py --systems cursor --role planner "development priorities and roadmap"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role planner "PRD creation and task generation"
```

##### **Implementer Role Context**
```bash
# Implementation context
python3 scripts/unified_memory_orchestrator.py --systems cursor --role implementer "development workflow and technical integration"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role implementer "system architecture and component integration"
```

##### **Researcher Role Context**
```bash
# Research context
python3 scripts/unified_memory_orchestrator.py --systems cursor --role researcher "research methodology and evidence-based analysis"
python3 scripts/unified_memory_orchestrator.py --scripts/unified_memory_orchestrator.py --systems cursor --role researcher "memory system optimization and performance analysis"
```

##### **Coder Role Context**
```bash
# Coding context
python3 scripts/unified_memory_orchestrator.py --systems cursor --role coder "implementation patterns and code quality"
python3 scripts/unified_memory_orchestrator.py --systems cursor --role coder "technical troubleshooting and debugging"
```

### **Role System Commands**

#### **Role Management Commands**
```bash
# List available roles
python3 scripts/list_cursor_roles.py --system cursor

# Configure role alignment
python3 scripts/configure_role_alignment.py --role planner --memory-system ltst

# Validate role integration
python3 scripts/validate_role_integration.py --role planner --full-check

# Test role functionality
python3 scripts/test_role_functionality.py --role planner --test-scenario planning
```

#### **Role Performance Commands**
```bash
# Measure role performance
python3 scripts/measure_role_performance.py --role planner --metrics response_time accuracy

# Optimize role configuration
python3 scripts/optimize_role_configuration.py --role planner --target-metrics performance

# Generate role report
python3 scripts/generate_role_report.py --role planner --output role_report.md

# Monitor role health
python3 scripts/monitor_role_health.py --role planner --real-time
```

### **Role System Quality Gates**

#### **Alignment Standards**
- **Memory Integration**: All roles must have seamless memory system access
- **Context Consistency**: Role responses must be consistent with memory context
- **Performance Optimization**: Role performance must meet established benchmarks
- **Workflow Alignment**: Role workflows must align with system processes

#### **Integration Requirements**
- **Configuration Quality**: Role configurations must be complete and valid
- **Memory Access**: All roles must have reliable access to memory systems
- **Response Quality**: Role responses must meet quality standards
- **Performance Monitoring**: Role performance must be continuously monitored

## ğŸ—„ï¸ **Database Troubleshooting Patterns**

### **ğŸš¨ CRITICAL: Database Troubleshooting Patterns are Essential**

**Why This Matters**: Database troubleshooting patterns provide systematic approaches to resolving database connection and DSPy system issues. Without proper troubleshooting patterns, system downtime increases, development productivity suffers, and system reliability is compromised.

### **Recurring Database Issues Pattern**

#### **1. PostgreSQL Service Issues**
**Pattern**: `postgresql@14 error` in brew services
**Symptoms**:
- `Error: failed to perform vector probe: pq: invalid input syntax for type vector`
- `Database connection error: 0`
- `No module named 'dspy_rag_system'`

**Recovery Steps**:
```bash
# 1. Check PostgreSQL status
brew services list | grep postgresql

# 2. Restart PostgreSQL service
brew services restart postgresql@14

# 3. Verify connection
psql -d postgres -c "SELECT version();"
```

#### **2. Database Schema Issues**
**Pattern**: Missing required columns or tables
**Symptoms**:
- `Database schema issue: Requires 'start_char' column that doesn't exist`
- `Table doesn't exist yet`

**Recovery Steps**:
```bash
# 1. Apply clean slate schema
psql -d postgres -f dspy-rag-system/config/database/clean_slate_schema.sql

# 2. Add missing columns
psql -d postgres -c "ALTER TABLE document_chunks ADD COLUMN IF NOT EXISTS start_char INTEGER;"

# 3. Verify schema
psql -d postgres -c "\d document_chunks"
```

#### **3. Vector Extension Issues**
**Pattern**: pgvector extension not properly installed
**Symptoms**:
- `pq: invalid input syntax for type vector`
- Vector operations failing

**Recovery Steps**:
```bash
# 1. Install vector extension
psql -d postgres -c "CREATE EXTENSION IF NOT EXISTS vector;"

# 2. Verify extension
psql -d postgres -c "\dx vector"
```

#### **4. Python Path Issues**
**Pattern**: Module import failures
**Symptoms**:
- `No module named 'dspy_rag_system'`
- Import errors in system health checks

**Recovery Steps**:
```bash
# 1. Set Python path
export PYTHONPATH="${PYTHONPATH}:$(pwd)/dspy-rag-system/src"

# 2. Verify imports
python3 -c "import dspy_rag_system; print('Import successful')"
```

#### **5. Database Connection Configuration**
**Pattern**: Missing or incorrect connection strings
**Symptoms**:
- `Database connection error: 0`
- Connection timeouts

**Recovery Steps**:
```bash
# 1. Set environment variables
export POSTGRES_DSN="postgresql://danieljacobs@localhost:5432/ai_agency?sslmode=disable"

# 2. Test connection
python3 -c "import psycopg2; print('Connection successful')"

# 3. Verify database access
psql -d ai_agency -c "SELECT COUNT(*) FROM document_chunks;"
```

### **Database Troubleshooting Commands**

#### **Service Management Commands**
```bash
# Check PostgreSQL status
brew services list | grep postgresql

# Restart PostgreSQL service
brew services restart postgresql@14

# Check PostgreSQL logs
tail -f /usr/local/var/log/postgresql@14.log

# Verify PostgreSQL version
psql -d postgres -c "SELECT version();"
```

#### **Schema Management Commands**
```bash
# Apply clean slate schema
psql -d postgres -f dspy-rag-system/config/database/clean_slate_schema.sql

# Check table structure
psql -d postgres -c "\d document_chunks"

# Add missing columns
psql -d postgres -c "ALTER TABLE document_chunks ADD COLUMN IF NOT EXISTS start_char INTEGER;"

# Verify schema integrity
python3 scripts/validate_database_schema.py --full-check
```

#### **Extension Management Commands**
```bash
# Install vector extension
psql -d postgres -c "CREATE EXTENSION IF NOT EXISTS vector;"

# List installed extensions
psql -d postgres -c "\dx"

# Verify vector extension
psql -d postgres -c "SELECT * FROM pg_extension WHERE extname = 'vector';"

# Test vector operations
psql -d postgres -c "SELECT '[1,2,3]'::vector;"
```

### **Database Troubleshooting Quality Gates**

#### **Service Standards**
- **Service Health**: PostgreSQL service must be running and healthy
- **Connection Reliability**: Database connections must be stable and fast
- **Error Handling**: Database errors must be properly logged and handled
- **Recovery Time**: Database issues must be resolved within established timeframes

#### **Schema Requirements**
- **Schema Completeness**: All required tables and columns must exist
- **Data Integrity**: Database constraints must be properly enforced
- **Extension Availability**: Required extensions must be properly installed
- **Performance Optimization**: Database queries must meet performance benchmarks

**Why This Matters**: System integration and deployment provide the mechanisms for connecting components, managing environments, and ensuring reliable system operation. Without proper integration and deployment, systems become fragmented, unreliable, and difficult to maintain.

### **System Integration Framework**

#### **Component Integration**
```python
class SystemIntegrationFramework:
    """Manages system component integration and communication."""

    def __init__(self):
        self.integration_patterns = {
            "api_gateway": "Centralized API gateway for service communication",
            "message_queue": "Asynchronous message-based communication",
            "event_bus": "Event-driven communication and coordination",
            "direct_integration": "Direct component-to-component communication"
        }
        self.integration_configs = {}

    def integrate_components(self, components: list, pattern: str = "api_gateway") -> dict:
        """Integrate system components using specified pattern."""

        if pattern not in self.integration_patterns:
            raise ValueError(f"Unknown integration pattern: {pattern}")

        # Validate component specifications
        if not self._validate_components(components):
            raise ValueError("Invalid component specifications")

        # Apply integration pattern
        integration_result = self._apply_integration_pattern(components, pattern)

        # Configure integration
        integration_config = self._configure_integration(integration_result, pattern)

        return {
            "integrated": True,
            "pattern_used": pattern,
            "integration_result": integration_result,
            "integration_config": integration_config
        }

    def _validate_components(self, components: list) -> bool:
        """Validate component specifications."""

        for component in components:
            required_fields = ["name", "interface", "dependencies"]
            for field in required_fields:
                if field not in component:
                    return False

        return True

    def _apply_integration_pattern(self, components: list, pattern: str) -> dict:
        """Apply specific integration pattern to components."""

        # Implementation for integration pattern application
        if pattern == "api_gateway":
            return self._apply_api_gateway_pattern(components)
        elif pattern == "message_queue":
            return self._apply_message_queue_pattern(components)
        elif pattern == "event_bus":
            return self._apply_event_bus_pattern(components)
        elif pattern == "direct_integration":
            return self._apply_direct_integration_pattern(components)

        return {"error": "Unknown integration pattern"}
```

#### **Deployment Management**
```python
class DeploymentManagementFramework:
    """Manages system deployment and environment management."""

    def __init__(self):
        self.deployment_environments = {
            "development": "Development environment for active development",
            "staging": "Staging environment for testing and validation",
            "production": "Production environment for live system operation"
        }
        self.deployment_strategies = {}

    def deploy_system(self, environment: str, deployment_config: dict) -> dict:
        """Deploy system to specified environment."""

        if environment not in self.deployment_environments:
            raise ValueError(f"Unknown deployment environment: {environment}")

        # Validate deployment configuration
        if not self._validate_deployment_config(deployment_config):
            raise ValueError("Invalid deployment configuration")

        # Prepare deployment
        deployment_prep = self._prepare_deployment(environment, deployment_config)

        # Execute deployment
        deployment_result = self._execute_deployment(deployment_prep)

        # Validate deployment
        validation_result = self._validate_deployment(deployment_result)

        return {
            "deployed": True,
            "environment": environment,
            "deployment_result": deployment_result,
            "validation_result": validation_result
        }

    def _validate_deployment_config(self, deployment_config: dict) -> bool:
        """Validate deployment configuration."""

        required_fields = ["version", "components", "dependencies"]

        for field in required_fields:
            if field not in deployment_config:
                return False

        return True
```

### **Integration & Deployment Commands**

#### **System Integration Commands**
```bash
# Integrate system components
python3 scripts/integrate_components.py --pattern api_gateway --components components.yaml

# Validate integration
python3 scripts/validate_integration.py --integration-id INT-001 --full-check

# Test component communication
python3 scripts/test_component_communication.py --components all --output communication_test.md

# Generate integration report
python3 scripts/generate_integration_report.py --output integration_report.md
```

#### **Deployment Management Commands**
```bash
# Deploy to environment
python3 scripts/deploy_system.py --environment staging --config deployment_config.yaml

# Validate deployment
python3 scripts/validate_deployment.py --environment staging --full-check

# Rollback deployment
python3 scripts/rollback_deployment.py --environment staging --version previous

# Generate deployment report
python3 scripts/generate_deployment_report.py --environment all --output deployment_report.md
```

### **Integration & Deployment Quality Gates**

#### **Integration Standards**
- **Component Compatibility**: All components must be compatible and interoperable
- **Interface Consistency**: Component interfaces must be consistent and well-defined
- **Communication Reliability**: Component communication must be reliable and efficient
- **Error Handling**: Proper error handling and recovery mechanisms must be in place

#### **Deployment Requirements**
- **Environment Validation**: All deployment environments must be properly configured
- **Configuration Management**: Deployment configurations must be version-controlled and validated
- **Rollback Capability**: Rollback mechanisms must be available for all deployments
- **Monitoring**: Comprehensive monitoring must be in place for all deployed systems

**Testing Infrastructure Guide**: `300_experiments/300_testing-infrastructure-guide.md`
- **Purpose**: Complete guide to testing environment and tools
- **Coverage**: Environment setup, testing workflows, debugging, CI/CD integration

**Testing Methodology Log**: `300_experiments/300_testing-methodology-log.md`
- **Purpose**: Central hub for all testing strategies and methodologies
- **Coverage**: Testing approaches, methodology evolution, key insights, performance tracking

**System Integration Testing**: `300_experiments/300_integration-testing-results.md`
- **Purpose**: Testing for system integration and cross-component functionality
- **Coverage**: End-to-end workflows, cross-system communication, error handling

## ğŸ“‹ Changelog
- 2025-08-28: Reconstructed full canonical overview; linked to detailed system overview and ops.
