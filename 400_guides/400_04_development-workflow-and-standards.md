# üîÑ Development Workflows & Standards

<!-- ANCHOR_KEY: development-workflow-standards -->
<!-- ANCHOR_PRIORITY: 5 -->
<!-- ROLE_PINS: ["implementer", "coder"] -->

## üîç TL;DR

| what this file is | read when | do next |
|---|---|---|
| Complete development workflow and coding standards for implementing features | Starting a new feature, implementing changes, or reviewing development process | Read 05 (Codebase Organization) then apply the workflow to your development |

- **what this file is**: End-to-end development workflow and coding standards for implementing features.

- **read when**: When starting a new feature, implementing changes, or reviewing development process.

- **do next**: Read 05 (Codebase Organization & Patterns) then apply the workflow to your development.

## üéØ **Current Status**
- **Priority**: üî• **HIGH** - Essential for development workflow
- **Phase**: 2 of 4 (Codebase Development)
- **Dependencies**: 03 (System Overview & Architecture)

## üéØ **Purpose**

Define the end-to-end development workflow (from idea to deployment) and the standards we enforce to keep quality high and changes safe.

## üìã When to Use This Guide

- Starting a new feature or refactor
- Planning or reviewing implementation steps
- Aligning on commit, review, and testing standards
- Preparing changes for deployment

## ‚úÖ Expected Outcomes

- Clear, repeatable workflow stages
- Consistent implementation and review standards
- Traceable commits tied to backlog items
- Changes that pass tests, link checks, and CI gates

## üß≠ Workflow (Idea ‚Üí Live)

1) Backlog and Scope
- Open or select a backlog item in `000_core/000_backlog.md`
- Confirm dependencies and acceptance criteria

2) Planning
- Read context from `400_00_getting-started-and-index.md` and `400_03_system-overview-and-architecture.md`
- For docs work, consult `400_01_documentation-playbook.md`

3) Implementation
- Follow code standards in `400_05_coding-and-prompting-standards.md`
- Use evidence-first edits and keep commits atomic

4) Testing
- Apply testing strategy from `400_05_coding-and-prompting-standards.md#testing-strategy-and-quality-gates`
- Ensure unit/integration/E2E coverage as appropriate

5) Security & Compliance
- Review `400_10_security-compliance-and-access.md` for security checks

6) Deployment & Ops
- Use `400_11_deployments-ops-and-observability.md` for rollout and validation

## üß± Detailed Workflow Stages

### Stage 1: Setup & Context
- Environment check: `python3 scripts/venv_manager.py --check`
- Memory rehydration: `./scripts/memory_up.sh -q "your task"`
- Quick conflict check: `python scripts/quick_conflict_check.py`
- **Cursor Git Integration Fix**: If you see "üîç Quick conflict check" messages during commits, use `git commit --no-verify` or `./scripts/commit_without_cursor.sh "message"` to bypass Cursor's built-in conflict detection

## üõ°Ô∏è **AI Constitution & Governance Rules**

### **üö® CRITICAL: AI Constitution Compliance**

**Why This Matters**: All AI operations must comply with the project's AI constitution to ensure safety, consistency, and proper governance. This is non-negotiable for system integrity.

### **Core AI Constitution Rules**

#### **1. Memory Context Preservation**
- **Context Rehydration**: Always run memory rehydration before AI operations
- **Cross-Session Continuity**: Maintain context across development sessions
- **Decision Tracking**: Record all AI decisions and their rationale
- **Context Validation**: Verify context integrity before proceeding

#### **2. Safety & Governance**
- **Input Validation**: All AI inputs must be validated and sanitized
- **Output Verification**: All AI outputs must be verified for safety and accuracy
- **Constitution Hooks**: AI prompts must include constitution compliance checks
- **Runtime Validation**: Continuous validation during AI operations

#### **3. Role-Based Access Control**
- **DSPy Role System**: Access AI capabilities through proper DSPy roles
- **Role-Specific Context**: Use role-appropriate context for different tasks
- **Permission Validation**: Verify role permissions before operations
- **Context Isolation**: Maintain role-specific context boundaries

#### **4. Error Handling & Recovery**
- **Graceful Degradation**: AI failures must not crash the system
- **Fallback Mechanisms**: Provide fallback options for AI failures
- **Error Logging**: Log all AI errors with context and recovery steps
- **Recovery Procedures**: Implement automatic recovery where possible

### **AI Constitution Implementation**

#### **Constitution Hooks in Prompts**
```python
# Example constitution-compliant prompt
constitution_prompt = f"""
{base_prompt}

üö® AI CONSTITUTION COMPLIANCE:
- Verify input safety and validation
- Ensure output accuracy and safety
- Maintain context integrity
- Follow role-specific guidelines
- Log all decisions and actions

CONTEXT: {current_context}
ROLE: {current_role}
SAFETY_LEVEL: {safety_level}
"""
```

#### **Runtime Constitution Validation**
```python
class ConstitutionValidator:
    """Validates AI operations against constitution rules."""

    def validate_input(self, input_data: str) -> bool:
        """Validate input against safety rules."""
        # Implementation details
        pass

    def validate_output(self, output_data: str) -> bool:
        """Validate output against safety rules."""
        # Implementation details
        pass

    def log_decision(self, decision: str, context: dict) -> None:
        """Log AI decision for audit trail."""
        # Implementation details
        pass
```

#### **Constitution Compliance Commands**
```bash
# Validate constitution compliance
python3 scripts/validate_constitution.py --check-all

# Check AI operation safety
python3 scripts/ai_safety_check.py --operation "your_operation"

# Validate context integrity
python3 scripts/validate_context.py --full-check

# Constitution compliance report
python3 scripts/constitution_report.py --output compliance_report.md
```

#### **Cursor Rules Integration**
- **Memory Rehydration Trigger**: `.cursorrules` automatically triggers `./scripts/memory_up.sh` at the start of new chats
- **Two Types of Cursor Rules**:
  - **Root Level**: `.cursorrules` - Contains memory rehydration trigger and core project rules
  - **Directory Level**: `.cursor/rules/` - Contains specialized rules for specific contexts
- **Automatic Context Loading**: Ensures AI has immediate access to project state, backlog, and system architecture
- **Role-Specific Context**: Memory rehydration includes role-specific information (planner, implementer, researcher, coder)

## üõ°Ô∏è **Governance-by-Code Insights**

### **üö® CRITICAL: Governance-by-Code is Essential**

**Why This Matters**: Governance-by-code provides automated, consistent enforcement of governance rules through CI/CD pipelines. Without automated governance, compliance becomes manual, error-prone, and unsustainable.

### **Core Governance-by-Code Principles**

#### **1. Single Source of Truth = CI**
- **Principle**: Docs explain; CI enforces
- **Application**: All governance rules must be automated in CI/CD pipelines
- **Avoid**: Manual checklists or documentation-only enforcement

#### **2. Small, Composable Tests > Giant End-to-End**
- **Principle**: If a check flakes, quarantine it fast
- **Application**: Build small, focused CI jobs that can be individually disabled
- **Avoid**: Monolithic validation systems that fail as a unit

#### **3. Budgets, Not Vibes**
- **Principle**: Every gate ties to a budget (latency p95, recall@k, token cost)
- **Application**: Define measurable thresholds for all governance gates
- **Avoid**: Subjective or qualitative enforcement criteria

#### **4. Progressive Hardening**
- **Principle**: Start permissive, move to required after 3‚Äì7 green runs
- **Application**: Begin with warn-only gates, flip to fail after proven stability
- **Avoid**: Starting with strict enforcement that blocks development

### **Memory System Evolution Insights**

#### **1. Markdown as Router, Not Encyclopedia**
- **Insight**: Point to RAG/CAG instead of restating facts
- **Application**: Turn 100_cursor-memory-context.md into thin index/map-of-maps
- **Benefit**: Freshness and confidence win by design

#### **2. RAG/CAG as Source of Truth**
- **Insight**: Vector DB provides facts, docs provide routing
- **Application**: Build ‚â§200-token hydration pins from RAG/CAG
- **Benefit**: Always current, always relevant

#### **3. Map-of-Maps for Structural Routing**
- **Insight**: Help Cursor AI navigate codebase efficiently
- **Application**: Extract module graphs, entrypoints, risk assessments
- **Benefit**: Surgical AI assistance instead of "read half the repo"

#### **4. Memory Events ‚Üí Facts ‚Üí Pins**
- **Insight**: Structured memory pipeline with budgets
- **Application**: Capture CI results, evals, vector health as events
- **Benefit**: Measurable, auditable memory system

### **Industry Best Practices**

#### **1. Policy-as-Code (IBM, AWS, Azure)**
- **Practice**: Embed governance in pipelines, not just documentation
- **Examples**: AWS Bedrock Guardrails, Azure Groundedness Detection
- **Application**: CI jobs enforce policies, not human review

#### **2. System Cards (OpenAI)**
- **Practice**: Lightly human-readable dashboards of behavior and metrics
- **Application**: Expose governance health via metrics and dashboards
- **Benefit**: Transparency and accountability

#### **3. Automated Risk Measurement**
- **Practice**: Continuous monitoring and measurement of AI system risks
- **Application**: Automated risk assessment and alerting systems
- **Benefit**: Proactive risk identification and mitigation

### **Governance-by-Code Commands**

#### **Governance Management Commands**
```bash
# Validate governance compliance
python3 scripts/validate_governance_compliance.py --policy ai_safety --full-check

# Test governance rules
python3 scripts/test_governance_rules.py --rule ethical_ai --test-scenario fairness

# Monitor governance health
python3 scripts/monitor_governance_health.py --real-time --output governance_report.md

# Generate governance report
python3 scripts/generate_governance_report.py --policy all --output governance_report.md
```

#### **CI/CD Integration Commands**
```bash
# Integrate governance into CI/CD
python3 scripts/integrate_governance_cicd.py --pipeline main --governance-policy ai_safety

# Test governance pipeline
python3 scripts/test_governance_pipeline.py --pipeline main --governance-rule ethical_ai

# Validate governance automation
python3 scripts/validate_governance_automation.py --pipeline main --full-check

# Monitor governance pipeline health
python3 scripts/monitor_governance_pipeline.py --pipeline main --real-time
```

### **Governance-by-Code Quality Gates**

#### **Automation Standards**
- **CI Integration**: All governance rules must be automated in CI/CD
- **Test Coverage**: Governance tests must have comprehensive coverage
- **Performance Budgets**: All governance gates must have measurable thresholds
- **Progressive Hardening**: Governance must start permissive and harden over time

#### **Compliance Requirements**
- **Policy Enforcement**: All policies must be automatically enforced
- **Risk Monitoring**: Continuous monitoring of AI system risks
- **Audit Trails**: Comprehensive logging of governance decisions
- **Performance Metrics**: Measurable governance performance indicators

## üí¨ **Communication Patterns Guide**

### **üö® CRITICAL: Communication Patterns are Essential**

**Why This Matters**: Communication patterns provide structured approaches for effective AI-user interaction and collaboration. Without proper communication patterns, interactions become inefficient, misunderstandings occur, and collaboration quality suffers.

### **Successful Communication Patterns**

#### **1. Strategic Discussion Format**
**Pattern**: Problem ‚Üí Analysis ‚Üí Strategy ‚Üí Questions
- **Problem**: Concrete metrics and clear pain points
- **Analysis**: Systematic breakdown of current state
- **Strategy**: Phased approach with clear benefits
- **Questions**: Invite collaboration rather than assumptions

**Example**:
```
üö® **The Problem is Real**: 51 files, 28,707 lines of documentation bloat
üí° **Proposed Strategy**: Apply README context management principles
üéØ **Expected Benefits**: Reduced cognitive load, improved quality
‚ùì **Questions for You**: What's your tolerance for automated changes?
```

#### **2. Structured Response Elements**
**Pattern**: Use consistent formatting that resonates
- **Clear sections** with emoji headers (üéØ, üí°, üöÄ, ‚ùì)
- **Concrete metrics** (file counts, line counts, performance numbers)
- **Actionable timeframes** (Week 1, Week 2, Phase 1, Phase 2)
- **Balanced approach** (not over-engineering, but thorough)

#### **3. User Preference Alignment**
**Pattern**: Match user's communication style
- **Strategic questions** rather than jumping to implementation
- **Systematic approaches** with clear phases
- **Incremental, testable changes** over big-bang solutions
- **Focus on "why" before "how"**

#### **4. Memory System Integration**
**Pattern**: Leverage memory context for personalization
- **Solo developer** in local-first environment
- **Simpler, streamlined approaches** preferred
- **Avoid overfitting or over-complication**
- **Plain, straightforward language**

### **Formatting Guidelines**

#### **Strategic Discussions**
```
## üß† **Strategic Analysis: [Topic]**

### **Current State Assessment**
- **Concrete metrics** and clear pain points
- **Systematic breakdown** of current state

### **Proposed Strategy**
- **Phased approach** with clear timeframes
- **Expected benefits** with specific outcomes

### **Key Design Decisions**
- **Options presented** rather than assumptions
- **Questions for collaboration** and input

### **Expected Benefits**
- **Concrete improvements** with metrics
- **Clear value proposition**
```

#### **Problem-Solution Format**
```
## üö® **The Problem is Real**
- **Specific metrics** (files, lines, performance)
- **Clear pain points** and impact

## üí° **The Opportunity**
- **Leverage existing successes** (like README context system)
- **Apply proven patterns** to new domains

## üéØ **Proposed Solution**
- **Systematic approach** with phases
- **Clear benefits** and outcomes
```

### **Communication Pattern Commands**

#### **Pattern Management Commands**
```bash
# List communication patterns
python3 scripts/list_communication_patterns.py --category strategic

# Apply communication pattern
python3 scripts/apply_communication_pattern.py --pattern strategic_discussion --context user_preferences

# Validate communication effectiveness
python3 scripts/validate_communication_effectiveness.py --pattern strategic_discussion --user-feedback feedback.json

# Generate communication report
python3 scripts/generate_communication_report.py --pattern all --output communication_report.md
```

#### **Pattern Quality Commands**
```bash
# Test communication pattern
python3 scripts/test_communication_pattern.py --pattern strategic_discussion --test-scenario planning

# Measure pattern effectiveness
python3 scripts/measure_communication_effectiveness.py --pattern strategic_discussion --metrics clarity engagement

# Generate pattern report
python3 scripts/generate_communication_pattern_report.py --pattern strategic_discussion --output pattern_report.md

# Monitor communication quality
python3 scripts/monitor_communication_quality.py --real-time --output quality_report.md
```

### **Communication Pattern Quality Gates**

#### **Pattern Standards**
- **Clarity**: All communication patterns must be clear and understandable
- **Effectiveness**: Patterns must improve communication quality and efficiency
- **Consistency**: Patterns must be consistently applied across interactions
- **User Alignment**: Patterns must align with user preferences and needs

#### **Communication Requirements**
- **Structure**: All communications must follow established patterns
- **Metrics**: Communications must include concrete metrics and data
- **Collaboration**: Communications must invite user input and collaboration
- **Quality**: All communications must meet established quality standards

#### 10-minute triage (from Comprehensive Guide)
- Merge markers: `git grep -nE '^(<<<<<<<|=======|>>>>>>>)'`
- Python deps: `python -m pip check`
- Node deps: `npm ls --all`
- Deep audit pointers: `python scripts/conflict_audit.py --full`, `python scripts/system_health_check.py --deep`

### Stage 2: Planning
- Assess code criticality (Tier 1‚Äì3) and affected modules
- Decide on reuse vs build per `400_05_coding-and-prompting-standards.md`
- Define test plan and acceptance criteria

### Stage 3: Implementation
- Follow coding patterns and guardrails in 05 (types, errors, structure)
- Keep edits atomic and evidence-first; reference sources in commit body
- Useful commands: `ruff check .`, `pyright .`, `ruff format .`

### Stage 4: Testing
- Unit, integration, and system tests as appropriate
- Coverage targets and quality gates per 05 testing strategy

## üìö **Documentation Playbook & File Management**

### **üö® MANDATORY: File Deletion/Deprecation Analysis**

**Before suggesting ANY file deletion, deprecation, or archiving, you MUST:**

1. **Complete 6-Step Mandatory Analysis** (from `400_01_documentation-playbook.md`)
2. **Show All Cross-References** - Prove you've done the analysis
3. **Get Explicit User Approval** - For any high-risk operations
4. **Follow Documentation Rules** - Use proper tiering and categorization

**üö® FAILURE TO FOLLOW THESE STEPS MEANS YOU CANNOT SUGGEST FILE OPERATIONS!**

### **6-Step Mandatory Analysis Process**

#### **Step 1: File Analysis Checklist**
```bash
# Run the analysis checklist
python3 scripts/file_analysis_checklist.py <target_file>

# Check for conflicts and dependencies
python3 scripts/quick_conflict_check.py
python3 scripts/conflict_audit.py --full
```

#### **Step 2: Cross-Reference Analysis**
- **Upstream Dependencies**: Files that reference this file
- **Downstream Dependencies**: Files this file references
- **Context Index**: Memory system integration points
- **Documentation Links**: Cross-references in guides

#### **Step 3: Impact Assessment**
- **Criticality Level**: Tier 1 (Critical), Tier 2 (High), Tier 3 (Supporting)
- **User Impact**: Who will be affected by this change
- **System Impact**: How this affects system functionality
- **Recovery Plan**: How to restore if needed

#### **Step 4: Documentation Rules Compliance**
- **Tier Classification**: Proper priority classification (0-12)
- **Role Pins**: Appropriate role assignments
- **Content Type**: Guide, reference, example, or archive
- **Cross-Reference Updates**: Update all related documentation

#### **Step 5: Implementation Planning**
- **Migration Strategy**: How to safely move/archive content
- **Rollback Plan**: How to undo if problems arise
- **Testing Plan**: How to validate the change
- **Communication Plan**: How to notify affected users

#### **Step 6: Execution & Validation**
- **Safe Execution**: Follow the planned approach
- **Validation**: Verify the change worked correctly
- **Cross-Reference Update**: Update all related documentation
- **Memory Context Update**: Update memory system integration

### **Documentation Tier System**

#### **Tier 1 (Critical - Priority 0-10)**
- **Core Memory Context**: `100_cursor-memory-context.md`
- **System Overview**: `400_03_system-overview-and-architecture.md`
- **Backlog Management**: `000_core/000_backlog.md`
- **Development Workflow**: This guide

#### **Tier 2 (High - Priority 15-20)**
- **AI Frameworks**: `400_09_ai-frameworks-dspy.md`
- **Performance Optimization**: `400_11_performance-optimization.md`
- **Code Organization**: `400_05_codebase-organization-patterns.md`

#### **Tier 3 (Supporting - Priority 25-30)**
- **Project Planning**: `400_07_project-planning-roadmap.md`
- **Task Management**: `400_08_task-management-workflows.md`
- **Advanced Configurations**: `400_12_advanced-configurations.md`

### **File Management Commands**

#### **Safe File Operations**
```bash
# Quick conflict check
python3 scripts/quick_conflict_check.py

# Comprehensive conflict audit
python3 scripts/conflict_audit.py --full

# File analysis checklist
python3 scripts/file_analysis_checklist.py <target_file>

# Documentation coherence validation
python3 scripts/doc_coherence_validator.py

# Memory context update
python3 scripts/update_cursor_memory.py
```

#### **Documentation Health Monitoring**
```bash
# Check documentation health
python3 scripts/documentation_health_check.py

# Validate cross-references
python3 scripts/validate_cross_references.py

# Check for broken links
python3 scripts/check_broken_links.py
```
- Run: `pytest tests/ -q` (see markers/tiers in repo)
- **RAGChecker Evaluation**: Run official RAGChecker evaluation for RAG system changes
  ```bash
  # Run Official RAGChecker evaluation
  python3 scripts/ragchecker_official_evaluation.py

  # Pre-commit RAGChecker validation
  python3 scripts/pre_commit_ragchecker.py

  # Check evaluation status
  cat metrics/baseline_evaluations/EVALUATION_STATUS.md

  # CI/CD automated evaluation (GitHub Actions)
  # Triggered automatically on RAGChecker-related changes
  ```

### Stage 5: Quality
- Code review checklist (function length, typing, errors, docs)
- CI dry-run validates lint, types, tests on PRs

### Stage 6: Deployment
- Pre-deploy checklist (tests/quality/perf/security) then rollout via 11

## üß© Standards

- Commits reference backlog IDs where applicable
- Documentation updated alongside code changes
- No broken links (link validation required)
- Consolidated guide links only (no links to archived 600_ files)
- Consistent section structure across guides

### Commit & Traceability
- Reference backlog IDs when applicable (e.g., B-xxxx)
- Summarize problem and resolution for housecleaning items

## üîß How-To (Common Tasks)

- Start a feature: align scope, create branch if required by policy, implement with small commits
- Update docs: follow `400_01_documentation-playbook.md` structure and cross-link patterns
- Add tests: consult testing gates in 05; keep tests fast and focused
- Run link validation: ensure all internal links resolve in 400_guides and 000/100/

### Development Commands
```bash
# Start development session
python3 scripts/single_doorway.py generate "feature description"

# Check code quality
ruff check . && pyright .

# Run tests
pytest tests/ -q
```

## üìù Checklists

- [ ] Backlog item selected and scoped
- [ ] Code follows 05 standards; types and naming are clear
- [ ] Tests added/updated and pass locally
- [ ] Links valid across docs (no references to removed files)
- [ ] Security considerations reviewed (10)
- [ ] Deployment plan confirmed (11)
- [ ] **RAGChecker evaluation run** for RAG system changes (if applicable)
- [ ] **CI/CD pipeline validation** for RAGChecker changes (automated)

## üîó Interfaces

- Backlog: `000_core/000_backlog.md`
- Memory System Overview: `400_guides/400_00_memory-system-overview.md`
- System Architecture: `400_guides/400_03_system-overview-and-architecture.md`
- Codebase Organization: `400_guides/400_05_codebase-organization-patterns.md`
- Security: `400_guides/400_10_security-compliance-and-access.md`
- Deployments/Ops: `400_guides/400_11_deployments-ops-and-observability.md`

## üìö References

- Documentation Playbook: `400_01_documentation-playbook.md`
- AI Frameworks (DSPy/MCP): `400_07_ai-frameworks-dspy.md`
- Integrations: `400_08_integrations-editor-and-models.md`
- Automation & Pipelines: `400_09_automation-and-pipelines.md`

## üß™ **Testing & Quality Assurance**

### **üö® CRITICAL: Testing & Quality Assurance are Essential**

**Why This Matters**: Testing and quality assurance ensure that all development work meets established standards, functions correctly, and maintains system reliability. Without proper testing, bugs proliferate, system stability degrades, and user experience suffers.

### **Testing Framework & Standards**

#### **Test Categories & Coverage**
- **Unit Tests**: Individual component testing with comprehensive coverage
- **Integration Tests**: Component interaction and system integration testing
- **Performance Tests**: System performance and scalability validation
- **Security Tests**: Security vulnerability and compliance testing
- **User Acceptance Tests**: End-user functionality and experience validation

#### **Quality Assurance Processes**
- **Code Review**: Peer review and automated quality checks
- **Static Analysis**: Code quality and security analysis
- **Dynamic Testing**: Runtime behavior and performance validation
- **Regression Testing**: Ensuring new changes don't break existing functionality

## üîß **Implementation Patterns Library**

### **üö® CRITICAL: Implementation Patterns are Essential**

**Why This Matters**: Implementation patterns provide reusable, proven solutions for common development tasks. Without proper pattern integration into memory context, AI agents cannot provide consistent, high-quality implementation guidance or leverage established best practices.

### **Pattern Library Categories**

#### **1. Memory System Patterns**

##### **Memory Rehydration Pattern**
```python
def memory_rehydration_pattern(query: str, role: str) -> Dict[str, Any]:
    """Standard pattern for memory rehydration."""
    # Set environment
    os.environ["POSTGRES_DSN"] = "mock://test"

    # Execute memory orchestration
    result = subprocess.run([
        "python3", "scripts/unified_memory_orchestrator.py",
        "--systems", "cursor",
        "--role", role,
        query
    ], capture_output=True, text=True)

    return json.loads(result.stdout)
```

##### **Context Integration Pattern**
```python
def context_integration_pattern(base_context: Dict[str, Any],
                               additional_context: Dict[str, Any]) -> Dict[str, Any]:
    """Standard pattern for integrating multiple context sources."""
    integrated_context = base_context.copy()

    # Merge additional context
    for key, value in additional_context.items():
        if key in integrated_context:
            if isinstance(integrated_context[key], list):
                integrated_context[key].extend(value)
            elif isinstance(integrated_context[key], dict):
                integrated_context[key].update(value)
            else:
                integrated_context[key] = value

    return integrated_context
```

#### **2. DSPy Integration Patterns**

##### **DSPy Module Pattern**
```python
from dspy import Module, InputField, OutputField

class StandardDSPyModule(Module):
    """Standard pattern for DSPy module implementation."""

    def __init__(self):
        super().__init__()
        self.input_field = InputField()
        self.output_field = OutputField()

    def forward(self, input_data):
        """Standard forward method pattern."""
        # Process input
        processed_input = self.process_input(input_data)

        # Generate output
        output = self.generate_output(processed_input)

        # Validate output
        validated_output = self.validate_output(output)

        return validated_output

    def process_input(self, input_data):
        """Process input data."""
        # Implementation specific to module
        pass

    def generate_output(self, processed_input):
        """Generate output from processed input."""
        # Implementation specific to module
        pass

    def validate_output(self, output):
        """Validate output quality."""
        # Implementation specific to module
        pass
```

#### **3. System Integration Patterns**

##### **API Integration Pattern**
```python
def api_integration_pattern(endpoint: str, data: Dict[str, Any],
                           headers: Dict[str, str] = None) -> Dict[str, Any]:
    """Standard pattern for API integration."""

    # Set default headers
    if headers is None:
        headers = {"Content-Type": "application/json"}

    # Prepare request
    request_data = json.dumps(data)

    # Execute request
    try:
        response = requests.post(endpoint, data=request_data, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        raise Exception(f"API integration failed: {str(e)}")
```

##### **Database Integration Pattern**
```python
def database_integration_pattern(query: str, parameters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
    """Standard pattern for database integration."""

    # Get database connection
    connection = get_database_connection()

    try:
        # Execute query
        cursor = connection.cursor()
        if parameters:
            cursor.execute(query, parameters)
        else:
            cursor.execute(query)

        # Fetch results
        results = cursor.fetchall()

        # Convert to list of dictionaries
        columns = [desc[0] for desc in cursor.description]
        return [dict(zip(columns, row)) for row in results]

    finally:
        connection.close()
```

### **Implementation Pattern Commands**

#### **Pattern Management Commands**
```bash
# List available patterns
python3 scripts/list_implementation_patterns.py --category memory_system

# Apply pattern to code
python3 scripts/apply_implementation_pattern.py --pattern memory_rehydration --target-file target.py

# Validate pattern implementation
python3 scripts/validate_pattern_implementation.py --pattern memory_rehydration --target-file target.py

# Generate pattern documentation
python3 scripts/generate_pattern_documentation.py --pattern memory_rehydration --output pattern_doc.md
```

#### **Pattern Quality Commands**
```bash
# Test pattern implementation
python3 scripts/test_pattern_implementation.py --pattern memory_rehydration --target-file target.py

# Measure pattern effectiveness
python3 scripts/measure_pattern_effectiveness.py --pattern memory_rehydration --target-file target.py

# Generate pattern report
python3 scripts/generate_pattern_report.py --pattern memory_rehydration --output pattern_report.md
```

### **Implementation Pattern Quality Gates**

#### **Pattern Standards**
- **Reusability**: Patterns must be reusable across different contexts
- **Effectiveness**: Patterns must provide proven, effective solutions
- **Documentation**: All patterns must be well-documented with examples
- **Testing**: All patterns must be thoroughly tested and validated

#### **Implementation Requirements**
- **Consistency**: Pattern implementations must be consistent across the codebase
- **Quality**: Pattern implementations must meet established quality standards
- **Performance**: Pattern implementations must not degrade system performance
- **Maintenance**: Pattern implementations must be maintainable and extensible

**Why This Matters**: Testing and quality assurance provide the foundation for reliable, maintainable, and high-quality software development. Without proper testing, code quality suffers, bugs proliferate, and system reliability is compromised.

### **Testing Framework**

#### **Test Strategy & Planning**
```python
class TestingFramework:
    """Comprehensive testing framework for development workflows."""

    def __init__(self):
        self.test_types = {
            "unit": "Unit tests for individual components",
            "integration": "Integration tests for component interaction",
            "system": "System tests for end-to-end functionality",
            "performance": "Performance tests for system efficiency",
            "security": "Security tests for system protection"
        }
        self.test_strategies = {}

    def plan_testing(self, project_scope: dict) -> dict:
        """Plan comprehensive testing strategy for project."""

        # Validate project scope
        if not self._validate_project_scope(project_scope):
            raise ValueError("Invalid project scope")

        # Define testing strategy
        testing_strategy = self._define_testing_strategy(project_scope)

        # Plan test execution
        test_execution_plan = self._plan_test_execution(testing_strategy)

        # Define quality gates
        quality_gates = self._define_quality_gates(testing_strategy)

        return {
            "testing_planned": True,
            "testing_strategy": testing_strategy,
            "test_execution_plan": test_execution_plan,
            "quality_gates": quality_gates
        }

    def _validate_project_scope(self, project_scope: dict) -> bool:
        """Validate project scope completeness."""

        required_fields = ["components", "complexity", "risk_level", "timeline"]

        for field in required_fields:
            if field not in project_scope:
                return False

        return True

    def _define_testing_strategy(self, project_scope: dict) -> dict:
        """Define comprehensive testing strategy."""

        # Implementation for testing strategy definition
        return {
            "test_coverage_target": 0.90,
            "test_types": list(self.test_types.keys()),
            "automation_level": "high",
            "quality_thresholds": {
                "unit_test_coverage": 0.95,
                "integration_test_coverage": 0.85,
                "system_test_coverage": 0.80
            }
        }
```

#### **Quality Assurance & Gates**
```python
class QualityAssuranceFramework:
    """Manages quality assurance and quality gates."""

    def __init__(self):
        self.quality_dimensions = {
            "functionality": "Functional correctness and completeness",
            "reliability": "System reliability and stability",
            "performance": "System performance and efficiency",
            "security": "System security and protection",
            "maintainability": "Code maintainability and readability"
        }
        self.quality_gates = {}

    def validate_quality_gates(self, quality_metrics: dict) -> dict:
        """Validate that all quality gates are met."""

        # Validate quality metrics
        if not self._validate_quality_metrics(quality_metrics):
            raise ValueError("Invalid quality metrics")

        # Check quality gates
        gate_results = {}
        for dimension, threshold in self.quality_dimensions.items():
            gate_results[dimension] = self._check_quality_gate(
                dimension, quality_metrics.get(dimension, {})
            )

        # Overall quality assessment
        overall_quality = self._assess_overall_quality(gate_results)

        return {
            "quality_validated": True,
            "gate_results": gate_results,
            "overall_quality": overall_quality,
            "recommendations": self._generate_quality_recommendations(gate_results)
        }

    def _validate_quality_metrics(self, quality_metrics: dict) -> bool:
        """Validate quality metrics completeness."""

        # Implementation for quality metrics validation
        return True  # Placeholder

    def _check_quality_gate(self, dimension: str, metrics: dict) -> dict:
        """Check if quality gate is met for specific dimension."""

        # Implementation for quality gate checking
        return {
            "passed": True,
            "score": 0.95,
            "threshold": 0.80,
            "details": f"Quality gate passed for {dimension}"
        }
```

### **Testing & Quality Commands**

#### **Testing Management Commands**
```bash
# Plan testing strategy
python3 scripts/plan_testing.py --project-scope project_scope.yaml --output testing_strategy.md

# Execute test suite
python3 scripts/execute_tests.py --test-type all --output test_results.json

# Generate test coverage report
python3 scripts/generate_coverage_report.py --output coverage_report.md

# Validate test quality
python3 scripts/validate_test_quality.py --test-results test_results.json
```

#### **Quality Assurance Commands**
```bash
# Validate quality gates
python3 scripts/validate_quality_gates.py --metrics quality_metrics.yaml --strict

# Generate quality report
python3 scripts/generate_quality_report.py --output quality_report.md

# Monitor quality trends
python3 scripts/monitor_quality_trends.py --timeframe 30d --output quality_trends.md

# Quality improvement recommendations
python3 scripts/generate_quality_recommendations.py --gate-results gate_results.json
```

### **Testing & Quality Quality Gates**

#### **Testing Standards**
- **Test Coverage**: Minimum 90% test coverage for all components
- **Test Quality**: All tests must be meaningful and maintainable
- **Automation**: High level of test automation required
- **Execution Time**: Tests must complete within acceptable time limits

#### **Quality Requirements**
- **Functionality**: All functional requirements must be met
- **Reliability**: System must be stable and reliable
- **Performance**: System must meet performance requirements
- **Security**: All security requirements must be satisfied
- **Maintainability**: Code must be maintainable and readable

## üîó Related

- Getting Started: `400_00_getting-started-and-index.md`
- Product & Roadmap: `400_12_product-management-and-roadmap.md`

## üìã Changelog
- 2025-08-28: Restored consolidated development workflow and standards guide.
