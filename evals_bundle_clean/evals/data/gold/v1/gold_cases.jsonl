{"id": "GOLD_001", "mode": "reader", "query": "How do I run the gold evaluation profile?", "tags": ["ops_health", "rag_qa_single"], "category": "ops", "gt_answer": "Use the command: env -u INGEST_RUN_ID -u CHUNK_VARIANT UV_PROJECT_ENVIRONMENT=.venv uv run python scripts/evaluation/ragchecker_official_evaluation.py --profile gold"}
{"id": "GOLD_002", "mode": "retrieval", "query": "What is the database connection pattern used in this project?", "tags": ["rag_qa_single"], "category": "arch", "expected_files": ["src/common/psycopg3_config.py"], "globs": ["src/common/*.py"]}
{"id": "GOLD_003", "mode": "reader", "query": "How do I check TimescaleDB telemetry tables?", "tags": ["ops_health"], "category": "ops", "gt_answer": "Query eval_run, eval_event, and eval_case_result tables using Psycopg3Config"}
{"id": "GOLD_004", "mode": "retrieval", "query": "What environment variables are needed for evaluation runs?", "tags": ["rag_qa_single"], "category": "config", "expected_files": ["scripts/configs/profiles/real.env", "scripts/configs/profiles/gold.env"], "globs": ["scripts/configs/profiles/*.env"]}
{"id": "GOLD_005", "mode": "reader", "query": "Where are evaluation results stored?", "tags": ["ops_health"], "category": "ops", "gt_answer": "Results are saved to evals/metrics/dspy_evaluations/ directory as JSON files"}
{"id": "GOLD_006", "mode": "retrieval", "query": "List the core workflow guides in 000_core.", "tags": ["rag_qa_single"], "category": "arch", "expected_files": ["000_core/001_PRD_TEMPLATE.md", "000_core/002_TASK-LIST_TEMPLATE.md", "000_core/003_EXECUTION_TEMPLATE.md"], "globs": ["000_core/*.md"]}
{"id": "GOLD_007", "mode": "reader", "query": "What is the eval harness entry script path?", "tags": ["smoke", "gold"], "category": "ops", "gt_answer": "scripts/evaluation/ragchecker_official_evaluation.py"}
{"id": "GOLD_008", "mode": "retrieval", "query": "Which env var selects the evaluation profile?", "tags": ["smoke", "gold"], "category": "config", "expected_files": ["scripts/evaluation/profiles/gold.py", "scripts/evaluation/profiles/real.py"], "globs": ["scripts/evaluation/profiles/*.py"]}
