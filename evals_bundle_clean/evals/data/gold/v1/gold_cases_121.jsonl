{"id": "gold_000", "query": "Give the high-level getting started index.", "gt_answer": "The high-level getting started index is located in 400_guides/400_00_memory-system-overview.md. This document provides the canonical entry point for understanding the memory system architecture, context management, and getting started guidance for new contributors.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_001", "query": "What is the main purpose of 400_guides/400_07_project-planning-roadmap.md?", "gt_answer": "The main purpose of 400_07_project-planning-roadmap.md is to provide a comprehensive project planning roadmap including capacity planning, available hours tracking, project milestones, and strategic direction for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_002", "query": "What is the main purpose of 400_guides/400_11_performance-optimization.md?", "gt_answer": "The main purpose of 400_11_performance-optimization.md is to document performance optimization strategies, including the per_file_cap() mechanism that limits chunks per file (default 5) to prevent one README from dominating results, configurable via PER_FILE_CAP environment variable.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_003", "query": "What is the per-file cap mechanism?", "gt_answer": "The per-file cap mechanism limits the number of chunks that can be retrieved from a single file during retrieval operations. It prevents large files (like README files) from dominating search results by capping the number of chunks per file to a configurable limit (default 5). This is controlled by the PER_FILE_CAP environment variable.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_004", "query": "What is the main purpose of 100_memory/100_cursor-memory-context.md?", "gt_answer": "The main purpose of 100_cursor-memory-context.md is to document the Cursor memory system integration, including memory rehydration protocols, context management workflows, and integration benefits for memory systems like LTST, Cursor, Go CLI, and Prime.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_005", "query": "What is the memory/context workflow system?", "gt_answer": "The memory/context workflow system consists of multiple integrated components: LTST (Long-term Semantic Tracking) for cross-session continuity, Cursor memory for IDE integration, Go CLI memory for command-line interface, and Prime as the primary memory orchestrator.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_006", "query": "What is the main purpose of 400_guides/400_02_memory-rehydration-context-management.md?", "gt_answer": "The main purpose of 400_02_memory-rehydration-context-management.md is to document memory rehydration and context management workflows, including integration benefits for memory systems, context preservation across sessions, and memory quality gates for ensuring system reliability.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_007", "query": "What are the codebase organization patterns?", "gt_answer": "The codebase organization patterns include structured folder prefixes (100_memory, 200_setup, 300_experiments, 400_guides, 500_research), descriptive file naming conventions, and consistent project structure guidelines for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_008", "query": "What is the main purpose of 400_guides/400_03_system-overview-and-architecture.md?", "gt_answer": "The main purpose of 400_03_system-overview-and-architecture.md is to provide a comprehensive system overview and architecture documentation, including database troubleshooting patterns, system components, and architectural decisions for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_009", "query": "What is the main purpose of 400_guides/400_05_codebase-organization-patterns.md?", "gt_answer": "The main purpose of 400_05_codebase-organization-patterns.md is to document codebase organization patterns, coding standards, and project structure guidelines. It includes information about following established workflows in the 000_core directory for creating PRDs, generating tasks, and processing task lists using documented procedures.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_010", "query": "What is the RRF fusion method?", "gt_answer": "RRF (Reciprocal Rank Fusion) is a method that combines multiple ranking lists using weighted reciprocal rank scoring. It uses a k parameter (typically 60) to normalize scores and combines dense vector search with sparse BM25 search using z-score normalization for improved retrieval accuracy.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_011", "query": "What is the main purpose of 000_core/002_TASK-LIST_TEMPLATE.md?", "gt_answer": "The main purpose of 002_TASK-LIST_TEMPLATE.md is to provide a standardized template for generating task lists in the AI development tasks project. It follows the established workflows in the 000_core directory for creating PRDs, generating tasks, and processing task lists using documented procedures.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_012", "query": "What is the main purpose of 500_research/500_b031-completion-summary.md?", "gt_answer": "The main purpose of 500_b031-completion-summary.md is to document the completion summary for task B-031, including test suite results, implementation details, and project milestones achieved during the development process.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_013", "query": "What setup documentation is available?", "gt_answer": "Setup documentation includes memory system architecture guides, test memory rehydration procedures, and system setup instructions. These documents provide comprehensive guidance for setting up and configuring the AI development tasks project environment.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_014", "query": "What is search optimization?", "gt_answer": "Search optimization in this project involves the HybridVectorStore which combines dense vector search with sparse BM25 search using z-score normalization and RRF fusion. This hybrid approach improves both precision and recall by leveraging the strengths of both retrieval methods.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_015", "query": "How do I run the runbook?", "gt_answer": "To run the runbook, use the query rewrite system in src/dspy_modules/retriever/query_rewrite.py. The system uses PHRASE_HINTS including db_workflows, ops_health, meta_ops, and rag_qa_single to boost precision without distorting BM25 search results.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_016", "query": "How does provenance tracking work?", "gt_answer": "Provenance tracking is implemented in scripts/monitoring/drift_detector.py which checks F1 floors, regression guards, and saves metrics to evals/latest_reader_metrics.json. It includes few-shot ID tracking, chunk variant identification, and leakage guards to prevent data contamination.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_017", "query": "What is the main purpose of 400_guides/400_01_memory-system-architecture.md?", "gt_answer": "The main purpose of 400_01_memory-system-architecture.md is to document the memory system architecture, including folder prefixes (100_memory, 200_setup, 300_experiments, 400_guides, 500_research), file naming conventions with descriptive names and category prefixes, and system integration patterns.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_018", "query": "What is the HybridVectorStore?", "gt_answer": "The HybridVectorStore is a vector storage system that combines multiple retrieval methods for improved search performance. It includes runtime guard-rails with RAM pressure checks to prevent memory exhaustion, and implements hybrid search capabilities for efficient document retrieval and ranking.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_019", "query": "What are the phrase hints for different tags?", "gt_answer": "Phrase hints for different tags include db_workflows, ops_health, meta_ops, and rag_qa_single. These hints are used in the query rewrite system to boost precision without distorting BM25 search results, helping to improve retrieval accuracy for specific types of queries.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_020", "query": "Which file describes the memory/context workflow?", "gt_answer": "The memory/context workflow is described in 400_guides/400_00_memory-system-overview.md. This document includes memory quality gates, context integrity checks, and comprehensive guidance for memory system operations including LTST, Cursor, Go CLI, and Prime memory systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_021", "query": "What is the provenance tracking system?", "gt_answer": "The provenance tracking system is implemented in scripts/monitoring/drift_detector.py which checks F1 floors, regression guards, and saves metrics to evals/latest_reader_metrics.json. This replaces the deprecated ci_gate_reader.py script.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_022", "query": "What are the naming conventions used in this repo?", "gt_answer": "The reranker model configuration is defined in src/settings.py with RERANKER_MODEL=\"BAAI/bge-reranker-v2-m3\" as the default. The model can be configured via environment variables and is used by the cross-encoder client for reranking retrieved documents.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_023", "query": "What are the current evaluation baseline targets?", "gt_answer": "The current evaluation baseline targets are: Precision >=0.20, Recall >=0.45, F1 Score >=0.22, and Faithfulness >=0.60. These metrics are enforced as absolute performance floors with no regressions allowed.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_024", "query": "Where are database troubleshooting patterns documented?", "gt_answer": "Database troubleshooting patterns are documented in the 400_guides directory. The RAG pipeline uses hybrid retrieval with RRF fusion, cross-encoder reranking, and context-aware generation with citation extraction for comprehensive database operations.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_025", "query": "What memory systems are integrated?", "gt_answer": "The integrated memory systems include LTST (Long-term Semantic Tracking) for cross-session continuity, Cursor memory for IDE integration, Go CLI memory for command-line interface, and Prime as the primary memory orchestrator. These systems work together to provide comprehensive memory management.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_026", "query": "How do I run the evaluation system?", "gt_answer": "To run the evaluation system, export the POSTGRES_DSN environment variable to point to your database, then use the appropriate evaluation commands. The system supports multiple profiles (gold, real, mock) and can be run using scripts in the scripts/evaluation/ directory with proper configuration.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_027", "query": "What is the main purpose of 400_guides/400_00_memory-system-overview.md?", "gt_answer": "The main purpose of 400_00_memory-system-overview.md is to provide a comprehensive overview of the memory system architecture, including memory quality gates, context integrity checks, and integration patterns for LTST, Cursor, Go CLI, and Prime memory systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_028", "query": "Show the DSPy development context TL;DR.", "gt_answer": "The DSPy development context TL;DR covers the integration of DSPy 3.0.1 with the project, including RAGChecker evaluation system with real DSPy RAG integration, oracle metrics, retrieval snapshots, and comprehensive case result normalization for evaluation purposes.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_029", "query": "How do I run the CI gate for reader?", "gt_answer": "Run the CI gate for reader using: source scripts/shell/deployment/throttle_free_eval.sh && uv run python scripts/evaluation/ragchecker_official_evaluation.py --use-bedrock --bypass-cli --stable. This runs the RAGChecker evaluation system with CI gate configuration for reader performance validation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_030", "query": "What are the DSPy integration patterns in 400_guides/400_09_ai-frameworks-dspy.md?", "gt_answer": "The DSPy integration patterns in 400_09_ai-frameworks-dspy.md include evaluation manifest templates with chunking configuration, model specifications, retrieval parameters, and evaluation thresholds for reproducible evaluations.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_031", "query": "How do I configure the reranker?", "gt_answer": "Model configuration settings are defined in multiple locations: src/settings.py for evaluation settings with RERANKER_MODEL=\"BAAI/bge-reranker-v2-m3\", src/schemas/eval.py for RerankerConfig with model=\"BAAI/bge-reranker-v2-m3\", and src/training/domain_tuning_pipeline.py for training configurations with cross_encoder_model=\"BAAI/bge-reranker-v2-m3\".", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_032", "query": "What are the RAGChecker baseline metrics?", "gt_answer": "The RAGChecker baseline metrics include Precision >=0.20, Recall >=0.45, F1 Score >=0.22, and Faithfulness >=0.60. These serve as absolute performance floors with no regressions allowed.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_033", "query": "How does the DSPy RAG pipeline work?", "gt_answer": "The DSPy RAG pipeline works by storing evaluation manifests in metrics/baseline_evaluations/ directory with timestamped versions and configuration metadata. It uses hybrid retrieval, cross-encoder reranking, and context-aware generation to provide accurate answers.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_034", "query": "What is the database connection configuration?", "gt_answer": "Database connections are configured using the POSTGRES_DSN environment variable pointing to a PostgreSQL database with pgvector extension. The system uses connection pooling and proper error handling for reliable database operations.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_035", "query": "What is the memory rehydration protocol?", "gt_answer": "The memory rehydration protocol involves using the 000_core/001_PRD_TEMPLATE.md template to create product requirements documents following the established workflow, including memory system initialization, context restoration, and cross-session continuity management.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_036", "query": "How do I configure the DSPy reader system?", "gt_answer": "The DSPy reader system is configured in src/dspy_modules/dspy_reader_program.py where the RAGAnswer class uses retrieval and reader components. It includes BootstrapFewShot teleprompter and compiles programs using the compile_and_save() function. The compiled programs are saved to the artifacts/dspy/ directory when the compilation process is run.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_037", "query": "Why do we demote docs/design subtrees slightly?", "gt_answer": "The evals/stable_build/config/reader_limits.yaml file specifies per_chunk=2, total_sentences=12, min_sentence_score=0.1, and abstain_threshold=0.05. These settings help balance retrieval precision and recall while maintaining quality thresholds.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_038", "query": "What is the main purpose of 400_guides/400_08_task-management-workflows.md?", "gt_answer": "The main purpose of 400_08_task-management-workflows.md is to document task management workflows, including task generation, execution protocols, and workflow automation for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_039", "query": "How do I run the evals?", "gt_answer": "To run evaluations, use: source scripts/shell/deployment/throttle_free_eval.sh && uv run python scripts/evaluation/ragchecker_official_evaluation.py --use-bedrock --bypass-cli --stable. This executes the RAGChecker evaluation system with the specified configuration for comprehensive testing.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_040", "query": "What is the evaluation manifest template?", "gt_answer": "Default chunk size is 450 tokens with 0.10 overlap ratio and Jaccard threshold of 0.8 for deduplication", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_041", "query": "What is the context consumption enforcement?", "gt_answer": "Context consumption enforcement uses build_reader_context() with compact=True and select_sentences() which scores and keeps ~10-12 best lines. This reduces noise for better precision and ensures answers are grounded in the retrieved context.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_042", "query": "What are the communication patterns in this project?", "gt_answer": "Communication patterns in this project include structured documentation, clear naming conventions, and established workflows for PRD creation, task generation, and execution. The project emphasizes clear communication through standardized templates and processes.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_043", "query": "List the core workflow guides in 000_core.", "gt_answer": "The core workflow guides in 000_core include PRD templates, task generation procedures, and execution protocols. The retriever system in dspy_modules/retriever/ uses fused query (short/title/BM25), MMR rerank, per-file cap, and sentence selection for comprehensive retrieval.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_044", "query": "Where do evaluation manifests live?", "gt_answer": "Evaluation manifests live in evals/manifest.yml which defines the clean_dspy entrypoint and specifies which files are included in the evaluation bundle for ingestion. The manifest controls which files are processed by the evaluation ingester.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_045", "query": "How do I configure system modules?", "gt_answer": "System modules are configured using standard configuration files and environment variables. The system supports modular configuration through scripts/configs/ directory for profiles and evals/stable_build/config/ directory for YAML files including reader limits, retriever weights, and evaluation thresholds. Configuration includes profile-specific .env files and YAML configuration files for different components.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_046", "query": "What is the memory system in this project?", "gt_answer": "The memory system in this project consists of multiple integrated components: LTST (Long-term Semantic Tracking) for cross-session continuity, Cursor memory for IDE integration, Go CLI memory for command-line interface, and Prime as the primary memory orchestrator. These systems work together to provide comprehensive memory management and context preservation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_047", "query": "How do I create a PRD?", "gt_answer": "To create a PRD (Product Requirements Document), use the 000_core/001_PRD_TEMPLATE.md template. Follow the established workflow in the 000_core directory for creating PRDs, generating tasks, and processing task lists using documented procedures.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_048", "query": "What is the main purpose of 400_guides/400_04_development-workflow-and-standards.md?", "gt_answer": "The main purpose of 400_04_development-workflow-and-standards.md is to document development workflows and standards, including coding conventions, testing requirements, and quality gates for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_049", "query": "What are the backlog management priorities?", "gt_answer": "Backlog management priorities include task prioritization, workflow automation, and project management strategies. The system emphasizes structured documentation, clear naming conventions, and established workflows for PRD creation, task generation, and execution.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_050", "query": "What are the model configuration settings?", "gt_answer": "Model configuration settings are defined in evals/stable_build/config/reader_limits.yaml and related configuration files. These settings include per_chunk=2, total_sentences=12, min_sentence_score=0.1, and abstain_threshold=0.05 for controlling reader behavior and performance.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_051", "query": "What is the main purpose of 400_guides/400_10_integrations-models.md?", "gt_answer": "The main purpose of 400_10_integrations-models.md is to document integrations and model configurations, including API integrations, model specifications, and integration patterns for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_052", "query": "How does multi-hop retrieval work with fusion?", "gt_answer": "Multi-hop retrieval works with fusion using scripts/utilities/cursor_memory_rehydrate.py with role and task parameters, and scripts/core/unified_memory_orchestrator.py for full system coordination. Export POSTGRES_DSN first to establish database connection.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_053", "query": "What is the main purpose of 400_guides/400_09_ai-frameworks-dspy.md?", "gt_answer": "The main purpose of 400_09_ai-frameworks-dspy.md is to document DSPy integration patterns, including BootstrapFewShot teleprompter usage, RAGAnswer module configuration, and evaluation system integration with metrics stored in metrics/baseline_evaluations/.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_054", "query": "What is BM25?", "gt_answer": "BM25 (Best Matching 25) is a probabilistic ranking function used in information retrieval. In this project, it is used as part of the hybrid search system alongside vector embeddings to improve search accuracy and recall.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_055", "query": "What is the chunking configuration for embeddings?", "gt_answer": "The chunking configuration for embeddings includes get_project_context, run_precision_eval, and query_memory functions. The MCP server runs on localhost:3000, and detailed setup instructions are available in the project documentation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_056", "query": "What is the sentence compaction process?", "gt_answer": "The sentence compaction process uses the documents table with path_tsv for directory semantics and document_chunks with embedding_text. It employs GIN-indexed tsvector for ts_rank operations with a weight of 32 to optimize search performance.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_057", "query": "How do I set up shell integration?", "gt_answer": "Shell integration setup involves configuring the canary percentage, which should not exceed 50% by default but is configurable via the max_percentage parameter. This ensures proper load balancing and system stability.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_058", "query": "Where are the model configuration settings defined?", "gt_answer": "Model configuration settings are defined in evals/stable_build/config/reader_limits.yaml which includes per_chunk=2, total_sentences=12, min_sentence_score=0.1, and abstain_threshold=0.05 for controlling reader behavior and performance.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_059", "query": "How does the retriever system work?", "gt_answer": "The retriever system works through query rewriting and channel-specific query building implemented in src/dspy_modules/retriever/query_rewrite.py. It uses tag hints for different query types (ops_health, db_workflows, meta_ops, rag_qa_single), phrase hints for database operations, and document hint parsing to extract repo slugs from queries. The system builds specialized queries for different retrieval channels based on the query content and context.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_060", "query": "What is the main purpose of database troubleshooting patterns?", "gt_answer": "Database troubleshooting patterns help diagnose and resolve issues with PostgreSQL, pgvector, and other database components. These patterns include connection troubleshooting, performance optimization, and schema validation procedures. The troubleshooting is handled through the database configuration in src/common/psycopg3_config.py and connection management utilities.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_061", "query": "What is the governance-by-code system?", "gt_answer": "The governance-by-code system implements the gate and promote system that validates F1 score, precision drift, latency, and oracle metrics before promoting DSPy compiled artifacts to production. This ensures quality and prevents regressions.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_062", "query": "Why do ops_health phrase hints include health check and shell init?", "gt_answer": "The ops_health phrase hints include health check and shell init because they are implemented in src/dspy_modules/retriever/rerank.py with mmr_rerank() using alpha=0.85 and per_file_penalty=0.10 to prevent single files from monopolizing top-K results.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_063", "query": "How do I configure pgvector for ANN operations?", "gt_answer": "To configure pgvector for ANN operations: 1) Install PostgreSQL and pgvector extension, 2) Configure vector optimizations in src/common/psycopg3_config.py, 3) Set up HNSW indexes for vector similarity search, 4) Configure connection parameters with vector optimizations for retrieval roles.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_064", "query": "What are the core steps emphasized under 200_setup?", "gt_answer": "The core steps under 200_setup include: 1) Install PostgreSQL and pgvector extension, 2) Configure database connections using src/common/psycopg3_config.py, 3) Set up environment variables and configuration files, 4) Run database schema setup scripts, 5) Configure DSPy modules and evaluation profiles.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_065", "query": "Show me the setup docs under 200_setup.", "gt_answer": "The setup documentation under 200_setup includes comprehensive guides for system initialization, configuration, and deployment. These documents provide step-by-step instructions for setting up the AI development tasks project environment.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_066", "query": "What is the retrieval tuning protocol?", "gt_answer": "The retrieval tuning protocol involves optimizing retrieval parameters including dense and BM25 top-k values, reranking thresholds, and hybrid search weights. This systematic approach improves precision and recall in the RAG system through iterative parameter adjustment and performance monitoring.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_067", "query": "What database choice is used in this project?", "gt_answer": "This project uses PostgreSQL with pgvector extension for vector operations. The database choice provides robust ACID compliance, excellent vector search capabilities, and strong ecosystem support for AI/ML applications.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_068", "query": "What is DSPy according to the AI frameworks documentation?", "gt_answer": "DSPy is a framework for programming with foundation models that provides structured approaches to building AI applications. It includes optimization techniques, evaluation methods, and integration patterns for building reliable AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_069", "query": "How do I configure evaluation thresholds?", "gt_answer": "Evaluation thresholds are configured in scripts/monitoring/drift_detector.py with MIN_F1_MICRO=0.35 and MIN_F1_TAG=0.25. RAGChecker baseline metrics are stored in metrics/baseline_evaluations/ directory.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_070", "query": "Which file summarizes backlog and priorities?", "gt_answer": "Memory rehydration is run using: ./scripts/shell/utilities/memory_up.sh -q \"current project status\" -r planner. This shell script restores memory context across sessions and can be customized with different queries and roles for specific memory rehydration needs.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_071", "query": "Point me to memory-related guides under 100_memory.", "gt_answer": "Memory-related guides under 100_memory include cursor memory context, memory rehydration protocols, and system architecture documentation. Deployment is blocked by F1 score below baseline, precision drift >2%, latency increase >15%, and oracle metrics below thresholds to ensure system quality.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_072", "query": "How do I create a vector index with IVFFLAT?", "gt_answer": "To create a vector index with IVFFLAT, use the unified memory orchestrator in scripts/core/unified_memory_orchestrator.py which coordinates LTST, Cursor, Go CLI, and Prime systems. This provides role-aware context bundles and manages vector index creation with proper configuration.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_073", "query": "What is the websearch tsquery function?", "gt_answer": "The websearch tsquery function is implemented in the database schema for full-text search capabilities. It uses PostgreSQL tsvector and tsquery functions for efficient text search operations on document content and metadata.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_074", "query": "What is PostgreSQL used for in this project?", "gt_answer": "PostgreSQL is used as the primary database with pgvector extension for vector operations. It provides robust ACID compliance, excellent vector search capabilities, and strong ecosystem support for AI/ML applications including embedding storage and similarity search.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_075", "query": "How do I run database migrations?", "gt_answer": "Database migrations are run using the migration scripts in the migrations/ directory. These scripts handle schema changes, index creation, and data transformations while maintaining database integrity and version control.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_076", "query": "How do I run memory rehydration?", "gt_answer": "Memory rehydration is run using: export POSTGRES_DSN=\"mock://test\" && uv run python scripts/core/unified_memory_orchestrator.py --systems ltst cursor go_cli prime --role planner \"task\". This restores memory context across sessions.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_077", "query": "What is the RAGChecker evaluation system?", "gt_answer": "The RAGChecker evaluation system is run using export POSTGRES_DSN=\"mock://test\" && uv run python scripts/core/unified_memory_orchestrator.py --systems ltst cursor go_cli prime --role planner \"task\". This system provides comprehensive evaluation capabilities with proper memory integration.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_078", "query": "What is the main purpose of 400_guides/400_06_backlog-management-priorities.md?", "gt_answer": "The main purpose of 400_06_backlog-management-priorities.md is to document backlog management priorities, including task prioritization, workflow automation, and project management strategies. It includes advanced model adaptation framework implementation for memory context system architecture research.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_079", "query": "What MCP tools are available in this project?", "gt_answer": "MCP tools available in this project include server health checks, comprehensive testing via scripts/utilities/test_mcp_server.py, and tool-specific testing via curl commands. DSPy 3.0.1 works directly with litellm 1.77.0 without needing a compatibility shim.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_080", "query": "What is the memory system architecture?", "gt_answer": "The memory system architecture consists of multiple integrated components: LTST (Long-term Semantic Tracking) for cross-session continuity, Cursor memory for IDE integration, Go CLI memory for command-line interface, and Prime as the primary memory orchestrator. This architecture provides comprehensive memory management and context preservation across different system components.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_081", "query": "How does the database schema work?", "gt_answer": "The database schema includes tables for documents, document_chunks, code_files, code_symbols, and conversation data. It uses pgvector for embeddings, GIN indexes for text search, and HNSW indexes for vector similarity search.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_082", "query": "What is the canary deployment percentage limit?", "gt_answer": "The canary deployment percentage limit is 50% by default, but it is configurable via the max_percentage parameter. This ensures that new deployments are gradually rolled out to prevent system-wide failures.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_083", "query": "What is the sentence selection process?", "gt_answer": "The sentence selection process uses src/dspy_modules/reader/sentence_select.py to score sentences by token overlap, phrase hits, and filename tokens. Configuration is managed through evals/stable_build/config/reader_limits.yaml for budgets and thresholds.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_084", "query": "What is the API design approach?", "gt_answer": "The API design follows RESTful principles with proper error handling, input validation, and response formatting. It includes versioning strategies, authentication mechanisms, and comprehensive documentation for all endpoints.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_085", "query": "What is DSPy in the AI frameworks context?", "gt_answer": "DSPy is a framework for programming with foundation models that provides structured approaches to building AI applications. It includes optimization techniques, evaluation methods, and integration patterns for reliable AI systems. The framework supports few-shot learning, prompt optimization, and systematic evaluation of AI applications.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_086", "query": "How do I test the MCP server?", "gt_answer": "To test MCP server functionality, use: curl http://localhost:3000/health to check server health, then curl -X POST http://localhost:3000/mcp/tools/call with JSON payload containing tool_name and arguments. The MCP server runs on port 3000 and provides endpoints for memory operations, file processing, and evaluation tools.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_087", "query": "How do I run the evaluations?", "gt_answer": "To run evaluations with specific profiles, use: source scripts/shell/deployment/throttle_free_eval.sh && uv run python scripts/evaluation/ragchecker_official_evaluation.py --profile real --use-bedrock --bypass-cli --stable. This runs the evaluation system with the real profile for full system testing.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_088", "query": "What is the gate and promote system?", "gt_answer": "The gate and promote system validates F1 score, precision drift, latency, and oracle metrics before promoting DSPy compiled artifacts to production. It ensures quality gates are met and prevents regressions in the system.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_089", "query": "What is the main purpose of 400_guides/400_12_advanced-configurations.md?", "gt_answer": "The main purpose of 400_12_advanced-configurations.md is to document advanced configuration options, including environment variables, system parameters, and optimization settings for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_090", "query": "What is the main purpose of 500_research/500_research-index.md?", "gt_answer": "The main purpose of 500_research-index.md is to provide an index of research documents, including literature reviews, implementation summaries, and analysis reports for the AI development tasks project.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_091", "query": "What is the main purpose of 500_research/500_research-summary.md?", "gt_answer": "The main purpose of 500_research-summary.md is to provide a comprehensive summary of research findings, including key insights, implementation recommendations, and future research directions.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_092", "query": "What is the main purpose of 500_research/500_dspy-research.md?", "gt_answer": "The main purpose of 500_dspy-research.md is to document DSPy research findings, including framework analysis, optimization techniques, and integration patterns for building reliable AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_093", "query": "What is the main purpose of 500_research/500_performance-research.md?", "gt_answer": "The main purpose of 500_performance-research.md is to document performance research findings, including optimization strategies, benchmarking results, and performance improvement recommendations.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_094", "query": "What is the main purpose of 500_research/500_integration-research.md?", "gt_answer": "The main purpose of 500_integration-research.md is to document integration research findings, including system integration patterns, API design principles, and interoperability solutions.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_095", "query": "What is the main purpose of 500_research/500_testing-research.md?", "gt_answer": "The main purpose of 500_testing-research.md is to document testing research findings, including test strategies, quality assurance methods, and validation techniques for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_096", "query": "What is the main purpose of 500_research/500_security-research.md?", "gt_answer": "The main purpose of 500_security-research.md is to document security research findings, including security best practices, vulnerability assessments, and protection mechanisms for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_097", "query": "What is the main purpose of 500_research/500_deployment-research.md?", "gt_answer": "The main purpose of 500_deployment-research.md is to document deployment research findings, including deployment strategies, infrastructure requirements, and operational considerations for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_098", "query": "What is the main purpose of 500_research/500_monitoring-research.md?", "gt_answer": "The main purpose of 500_monitoring-research.md is to document monitoring research findings, including observability strategies, performance monitoring, and system health tracking for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_099", "query": "What is the main purpose of 500_research/500_migration-research.md?", "gt_answer": "The main purpose of 500_migration-research.md is to document migration research findings, including migration strategies, data transformation techniques, and system upgrade procedures.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_100", "query": "What is the main purpose of 500_research/500_metadata-research.md?", "gt_answer": "The main purpose of 500_metadata-research.md is to document metadata research findings, including metadata management strategies, data lineage tracking, and information architecture for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_101", "query": "What is the main purpose of 500_research/500_memory-arch-research.md?", "gt_answer": "The main purpose of 500_memory-arch-research.md is to document memory architecture research findings, including memory management strategies, caching techniques, and performance optimization for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_102", "query": "What is the main purpose of 500_research/500_memory-arch-literature.md?", "gt_answer": "The main purpose of 500_memory-arch-literature.md is to document memory architecture literature review, including academic research, industry best practices, and theoretical foundations for memory systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_103", "query": "What is the main purpose of 500_research/500_memory-arch-benchmarks.md?", "gt_answer": "The main purpose of 500_memory-arch-benchmarks.md is to document memory architecture benchmarks, including performance comparisons, scalability tests, and optimization results for memory systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_104", "query": "What is the main purpose of 500_research/500_few-shot-research.md?", "gt_answer": "The main purpose of 500_few-shot-research.md is to document few-shot learning research findings, including prompt engineering techniques, example selection strategies, and performance optimization for few-shot scenarios.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_105", "query": "What is the main purpose of 500_research/500_context-engineering-research.md?", "gt_answer": "The main purpose of 500_context-engineering-research.md is to document context engineering research findings, including context optimization techniques, prompt design strategies, and context management for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_106", "query": "What is the main purpose of 500_research/500_rag-system-research.md?", "gt_answer": "The main purpose of 500_rag-system-research.md is to document RAG system research findings, including retrieval optimization, generation quality improvement, and system integration patterns for retrieval-augmented generation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_107", "query": "What is the main purpose of 500_research/500_ai-retrieval-literature.md?", "gt_answer": "The main purpose of 500_ai-retrieval-literature.md is to document AI retrieval literature review, including academic research, industry best practices, and theoretical foundations for AI-powered retrieval systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_108", "query": "What is the main purpose of 500_research/500_agent-orchestration-research.md?", "gt_answer": "The main purpose of 500_agent-orchestration-research.md is to document agent orchestration research findings, including multi-agent coordination, task distribution strategies, and system architecture for agent-based AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_109", "query": "What is the main purpose of 500_research/500_augmentation-semantic-processes-research-summary.md?", "gt_answer": "The main purpose of 500_augmentation-semantic-processes-research-summary.md is to document augmentation semantic processes research summary, including semantic enhancement techniques, process optimization, and system integration for augmented AI workflows.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_110", "query": "What is the main purpose of 500_research/500_comprehensive-benchmark-analysis-task-3-1.md?", "gt_answer": "The main purpose of 500_comprehensive-benchmark-analysis-task-3-1.md is to document comprehensive benchmark analysis findings, including performance comparisons, scalability assessments, and optimization recommendations for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_111", "query": "What is the main purpose of 500_research/500_performance-analysis-optimization-opportunities-task-3-2.md?", "gt_answer": "The main purpose of 500_performance-analysis-optimization-opportunities-task-3-2.md is to document performance analysis and optimization opportunities, including bottleneck identification, improvement strategies, and system enhancement recommendations.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_112", "query": "What is the main purpose of 500_research/500_proof-of-concept-implementation-task-5-1.md?", "gt_answer": "The main purpose of 500_proof-of-concept-implementation-task-5-1.md is to document proof-of-concept implementation findings, including prototype development, validation results, and feasibility assessments for new AI system components.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_113", "query": "What is the main purpose of 500_research/500_proof-of-concept-validation-task-5-2.md?", "gt_answer": "The main purpose of 500_proof-of-concept-validation-task-5-2.md is to document proof-of-concept validation findings, including testing results, performance metrics, and validation criteria for new AI system components.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_114", "query": "What is the main purpose of 500_research/500_overflow-handling-implementation-task-6-1.md?", "gt_answer": "The main purpose of 500_overflow-handling-implementation-task-6-1.md is to document overflow handling implementation findings, including capacity management strategies, error handling techniques, and system resilience improvements.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_115", "query": "What is the main purpose of 500_research/500_automated-performance-monitoring-task-6-4.md?", "gt_answer": "The main purpose of 500_automated-performance-monitoring-task-6-4.md is to document automated performance monitoring implementation, including monitoring strategies, alerting mechanisms, and performance tracking systems for AI applications.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_116", "query": "What is the main purpose of 500_research/500_comprehensive-documentation-suite-task-6-3.md?", "gt_answer": "The main purpose of 500_comprehensive-documentation-suite-task-6-3.md is to document comprehensive documentation suite development, including documentation strategies, content organization, and maintenance procedures for AI system documentation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_117", "query": "What is the main purpose of 500_research/500_advanced-model-adaptation-framework-task-6-2.md?", "gt_answer": "The main purpose of 500_advanced-model-adaptation-framework-task-6-2.md is to document advanced model adaptation framework development, including adaptation strategies, fine-tuning techniques, and model optimization for specific use cases.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_118", "query": "What is the main purpose of 500_research/500_advanced-resilience-patterns-task-7-1.md?", "gt_answer": "The main purpose of 500_advanced-resilience-patterns-task-7-1.md is to document advanced resilience patterns implementation, including fault tolerance strategies, recovery mechanisms, and system robustness improvements for AI systems.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_119", "query": "What is the main purpose of 500_research/500_advanced-analytics-insights-task-7-2.md?", "gt_answer": "The main purpose of 500_advanced-analytics-insights-task-7-2.md is to document advanced analytics insights development, including data analysis techniques, insight generation methods, and analytical framework implementation for AI system optimization.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "retrieval"}
{"id": "gold_120", "query": "What is the main purpose of 500_research/500_model-specific-testing-framework-analysis.md?", "gt_answer": "The main purpose of 500_model-specific-testing-framework-analysis.md is to document model-specific testing framework analysis, including testing strategies, validation methods, and quality assurance techniques for AI model evaluation.", "tags": ["comprehensive", "gold", "evaluation"], "mode": "reader"}
{"id": "gold_122", "query": "How do evaluation profiles work in this system?", "gt_answer": "Evaluation profiles are implemented in scripts/evaluation/profiles/ with separate modules for gold.py, real.py, and mock.py. The gold profile uses CleanDSPyEvaluator with gold cases for baseline enforcement and PR gates. Each profile has specific configuration settings and error handling for different evaluation scenarios.", "tag": "retrieval"}
{"id": "gold_123", "query": "What is the gold evaluation profile configuration?", "gt_answer": "The gold evaluation profile is configured in scripts/configs/profiles/gold.env with real RAG system settings, Bedrock model configuration, and gold cases specific settings. It includes DSPY_RAG_PATH=src, EVAL_DRIVER=dspy_rag, RAGCHECKER_USE_REAL_RAG=1, and conservative Bedrock settings for stable evaluation runs.", "tag": "retrieval"}
{"id": "gold_124", "query": "How are environment configurations managed?", "gt_answer": "Environment configurations are managed through profile-specific .env files in scripts/configs/profiles/ including gold.env, real.env, and mock.env. These files contain database connections, model settings, evaluation parameters, and UV environment configurations for different evaluation scenarios.", "tag": "retrieval"}
{"id": "gold_125", "query": "What does the gold.py evaluation profile do?", "gt_answer": "The gold.py evaluation profile in scripts/evaluation/profiles/gold.py runs CleanDSPyEvaluator with gold cases for comprehensive evaluation. It includes error handling for import failures, runtime issues, and provides critical feedback for CI/CD pipeline blocking. The profile is essential for baseline enforcement and PR gates.", "tag": "reader"}
{"id": "gold_126", "query": "What does the gold evaluation profile script do?", "gt_answer": "The gold evaluation profile script in scripts/evaluation/profiles/gold.py runs CleanDSPyEvaluator with gold cases for comprehensive evaluation. It includes error handling for import failures and runtime issues, providing critical feedback for CI/CD pipeline blocking. The profile is essential for baseline enforcement and PR gates.", "tag": "reader"}
{"id": "gold_127", "query": "What are the gold profile environment settings?", "gt_answer": "The gold profile environment settings in scripts/configs/profiles/gold.env include DSPY_RAG_PATH=src, EVAL_DRIVER=dspy_rag, RAGCHECKER_USE_REAL_RAG=1, conservative Bedrock settings, and gold cases specific configuration. It configures the evaluation system for stable, production-like testing with real RAG components.", "tag": "retrieval"}
{"id": "gold_128", "query": "What are the real profile environment settings?", "gt_answer": "The real profile environment settings in scripts/configs/profiles/real.env configure the evaluation system for full system testing with real project data. It includes database connections, model configurations, and evaluation parameters optimized for comprehensive testing scenarios.", "tag": "retrieval"}
{"id": "gold_129", "query": "How does DSN resolution work in the system?", "gt_answer": "DSN resolution is handled by src/common/psycopg3_config.py which provides centralized database connection management. It uses resolve_dsn() for DSN resolution, includes connection parameters optimized for AI Dev Tasks, and provides vector-specific optimizations for retrieval roles.", "tag": "retrieval"}
{"id": "gold_130", "query": "What is the throttle script used for?", "gt_answer": "The throttle script scripts/shell/deployment/throttle_free_eval.sh is used to control evaluation execution and resource usage. It provides throttling mechanisms for evaluation runs, manages concurrency limits, and ensures stable evaluation performance by controlling the rate of evaluation requests.", "tag": "retrieval"}
